# 01 - 背景知識 (Background Knowledge)

Born2beRoot プロジェクトに必要な全ての基礎概念を網羅的に解説する。単なる設定方法の羅列ではなく、各技術が「なぜ」必要なのか、内部でどのように動作しているのかを深く掘り下げる。

---

## 1. 仮想化 (Virtualization)

### 1.1 仮想化とは何か

仮想化とは、物理的なハードウェアリソース（CPU、メモリ、ストレージ、ネットワーク）を抽象化し、複数の仮想環境を一つの物理マシン上で動作させる技術である。各仮想環境は独立した「仮想マシン (Virtual Machine, VM)」として動作し、それぞれが独自のオペレーティングシステムとアプリケーションを実行できる。

仮想化の主な利点:

- **リソースの効率的利用**: 一台の物理サーバーで複数の VM を動作させることで、ハードウェアの使用率を最大化する。物理サーバーの平均CPU利用率は15-20%程度と言われており、仮想化によって60-80%まで引き上げることが可能
- **分離性 (Isolation)**: 各 VM は互いに独立しており、一つの VM の障害が他に影響しない。これはマルチテナント環境（クラウドサービス）で特に重要
- **移植性 (Portability)**: VM は仮想ディスクファイルとして保存され、別のホストに移動可能。OVF (Open Virtualization Format) 形式で異なるハイパーバイザー間での移行も可能
- **スナップショット**: 任意の時点の状態を保存・復元できる。設定変更前にスナップショットを取得しておけば、問題が発生しても即座に元の状態に戻せる
- **テスト環境**: 本番環境に影響を与えずに安全にテストできる。Born2beRoot はこの特性を最大限に活用するプロジェクト

### 1.2 仮想化の歴史 - メインフレーム時代からクラウドまで

仮想化技術は新しい概念ではない。その歴史は1960年代にまで遡り、コンピュータサイエンスの発展とともに進化してきた。

#### 1960年代 - メインフレーム時代の幕開け

1960年代、コンピュータは非常に高価であり、一台のメインフレームを複数のユーザーが共有する必要があった。この時代に仮想化の基礎概念が生まれた。

```
1960年代のメインフレーム環境:

┌─────────────────────────────────────────────────────┐
│              IBM System/360 メインフレーム            │
│                                                      │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐  │
│  │ User A  │ │ User B  │ │ User C  │ │ User D  │  │
│  │ の仮想  │ │ の仮想  │ │ の仮想  │ │ の仮想  │  │
│  │ マシン  │ │ マシン  │ │ マシン  │ │ マシン  │  │
│  └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘  │
│       │           │           │           │         │
│  ┌────┴───────────┴───────────┴───────────┴────┐    │
│  │          CP (Control Program)               │    │
│  │          = 初期のハイパーバイザー             │    │
│  └─────────────────────────────────────────────┘    │
│                                                      │
│  ┌──────┐ ┌──────┐ ┌──────────┐ ┌──────────────┐   │
│  │ CPU  │ │ RAM  │ │ Disk     │ │ Card Reader  │   │
│  │      │ │      │ │ (DASD)   │ │ / Printer    │   │
│  └──────┘ └──────┘ └──────────┘ └──────────────┘   │
└─────────────────────────────────────────────────────┘
```

主要なマイルストーン:

- **1964年**: IBM が **CP-40** (Control Program-40) を開発。これは世界初の完全仮想化システムであり、IBM System/360 Model 40 上で動作した。各ユーザーに独立した仮想マシン環境を提供し、時分割処理（タイムシェアリング）を実現した
- **1966年**: IBM が **CP-67** を開発。CP-40 の後継で、System/360 Model 67 上で動作。仮想メモリのハードウェアサポートを利用した最初のシステム
- **1967年**: CP-67 上で動作する **CMS (Cambridge Monitor System)** が開発される。各ユーザーの仮想マシン内で動作する軽量OSで、対話型コンピューティングを実現

#### 1970年代 - 商用仮想化の確立

- **1972年**: IBM が **VM/370** をリリース。これは商用仮想化の始まりとなった。VM/370 は CP (Control Program) と CMS を組み合わせたシステムで、メインフレームのリソースを効率的に分割した
- **1974年**: Gerald J. Popek と Robert P. Goldberg が「仮想化可能なアーキテクチャの形式的要件」を発表。これは仮想化の理論的基盤となる重要な論文で、以下の3つの要件を定義した:
  1. **等価性 (Equivalence)**: VM 内のプログラムは、実機と同じ結果を出す
  2. **効率性 (Efficiency)**: 大部分の命令はハードウェアで直接実行される
  3. **リソース制御 (Resource Control)**: ハイパーバイザーがリソースを完全に制御する

```
Popek-Goldberg の仮想化要件:

命令セットの分類:
┌─────────────────────────────────────────────┐
│                 全命令セット                  │
│  ┌──────────────────────────────────────┐   │
│  │          特権命令 (Privileged)        │   │
│  │  Ring 0 でのみ実行可能               │   │
│  │  例: I/O命令、メモリ保護設定          │   │
│  │                                      │   │
│  │  ┌──────────────────────────────┐    │   │
│  │  │  機密命令 (Sensitive)         │    │   │
│  │  │  VM の挙動に影響を与える命令  │    │   │
│  │  │                              │    │   │
│  │  │  仮想化可能な条件:            │    │   │
│  │  │  全ての機密命令 ⊆ 特権命令   │    │   │
│  │  └──────────────────────────────┘    │   │
│  └──────────────────────────────────────┘   │
│                                              │
│  非特権命令: Ring 3 でも実行可能             │
│  例: ADD, MOV, CMP 等の演算命令             │
└─────────────────────────────────────────────┘

x86 の問題:
  x86 アーキテクチャでは、一部の機密命令が特権命令に
  含まれない（例: SGDT, SIDT, POPF）
  → ソフトウェアによる仮想化が必要だった
  → これが 2006年の VT-x/AMD-V で解決された
```

#### 1980-1990年代 - PC時代と仮想化の停滞

PC（パーソナルコンピュータ）の普及により、一人一台のコンピュータが当たり前になった。この時代は仮想化への関心が薄れた時期でもある。

- **1985年**: Insignia Solutions が SoftPC を開発。Mac 上で DOS を実行するエミュレータ
- **1988年**: Connectix が Virtual PC を開発（後に Microsoft が買収）
- **1990年代前半**: x86 アーキテクチャは Popek-Goldberg の要件を満たさず、完全な仮想化は困難とされていた

#### 1998-2005年 - x86 仮想化の実現

- **1998年**: **VMware** が創業。x86 アーキテクチャでの仮想化を、バイナリトランスレーション（機密命令を安全な命令列に動的に変換）によって実現した。これは画期的な技術であった
- **1999年**: VMware Workstation 1.0 リリース
- **2001年**: VMware ESX Server 1.0 リリース（Type 1 Hypervisor）
- **2003年**: **Xen** がオープンソースハイパーバイザーとしてリリース。準仮想化（Para-virtualization）アプローチを採用し、ゲスト OS のカーネルを修正して仮想化のオーバーヘッドを削減
- **2005年**: Xen 3.0 がリリースされ、ハードウェア仮想化支援（HVM）をサポート

```
バイナリトランスレーション (VMware のアプローチ):

ゲスト OS のコード:
  MOV CR3, EAX      ← 特権命令（ページテーブルの変更）
  SGDT [mem]        ← 機密だが非特権の命令

変換後のコード:
  CALL vmm_handler   ← ハイパーバイザーのハンドラを呼び出す
  CALL vmm_sgdt      ← 仮想化された SGDT の結果を返す

準仮想化 (Xen のアプローチ):
  ゲスト OS カーネルを修正:
  - 特権命令を hypercall（ハイパーバイザーへの呼び出し）に置換
  - 例: MOV CR3, EAX → HYPERCALL_mmu_update()
  - オーバーヘッドが小さいが、ゲスト OS の修正が必要
```

#### 2006年以降 - ハードウェア仮想化支援とクラウドの時代

- **2006年**: Intel が **VT-x** (Virtualization Technology for x86)、AMD が **AMD-V** (AMD Virtualization) をリリース。CPU レベルで仮想化を支援する機能が追加された

```
ハードウェア仮想化支援 (Intel VT-x) の仕組み:

従来の x86 (Ring 構造):
┌────────────────────────┐
│  Ring 3: アプリケーション│
│  Ring 2: (未使用)       │
│  Ring 1: (未使用)       │
│  Ring 0: OS カーネル    │
└────────────────────────┘

VT-x 導入後 (VMX モード):
┌────────────────────────┐
│  VMX non-root mode     │  ← ゲスト OS が動作
│  ┌──────────────────┐  │
│  │ Ring 3: アプリ   │  │
│  │ Ring 0: ゲストOS │  │  ← ゲスト OS は Ring 0 で動作可能
│  └──────────────────┘  │     (ただし VMX non-root mode)
├────────────────────────┤
│  VMX root mode         │  ← ハイパーバイザーが動作
│  ┌──────────────────┐  │
│  │ Ring 0: VMM      │  │
│  └──────────────────┘  │
└────────────────────────┘

VM Entry: root mode → non-root mode (ゲストの実行開始)
VM Exit:  non-root mode → root mode (特権操作のトラップ)

VMCS (Virtual Machine Control Structure):
  ゲストの状態（レジスタ値等）を保存する領域
  VM Entry/Exit 時に自動的にレジスタを保存・復元
```

- **2007年**: **KVM (Kernel-based Virtual Machine)** が Linux カーネル 2.6.20 に統合。Linux カーネル自体をハイパーバイザーとして機能させる
- **2007年**: **VirtualBox** がオープンソース化（Sun Microsystems、後に Oracle が買収）
- **2006年**: **Amazon EC2 (Elastic Compute Cloud)** がベータサービスを開始。クラウドコンピューティングの商用化が本格的に始まる
- **2008年**: **Google App Engine** がサービス開始
- **2010年**: **Microsoft Azure** が正式サービス開始
- **2010年**: **OpenStack** プロジェクトが開始（NASA と Rackspace が共同で）
- **2013年**: **Docker** がリリース。コンテナ仮想化の爆発的普及が始まる
- **2014年**: **Kubernetes** が Google からリリース。コンテナオーケストレーションの標準に
- **2017年**: AWS が **Nitro System** を導入。KVM ベースのハイパーバイザーに移行
- **2020年**: Apple Silicon (M1) の登場により、ARM ベースの仮想化が注目される

```
仮想化技術の進化の年表:

1964        1972        1998     2003   2006    2007   2013   2017
  │           │           │       │      │       │      │      │
  ▼           ▼           ▼       ▼      ▼       ▼      ▼      ▼
CP-40      VM/370     VMware    Xen   VT-x    KVM   Docker  Nitro
(IBM)      (IBM)      創業             AMD-V
                                               VBox
メインフレーム時代──→  x86仮想化の実現 ──→  クラウド/コンテナ時代
```

### 1.3 Hypervisor の種類

仮想化を実現するソフトウェアを **Hypervisor（ハイパーバイザー）** と呼ぶ。Hypervisor は大きく2種類に分類される。

#### Type 1 Hypervisor (Bare-metal Hypervisor)

物理ハードウェア上に直接インストールされ、ホスト OS を必要としない。

```
┌─────────┐ ┌─────────┐ ┌─────────┐
│  VM 1   │ │  VM 2   │ │  VM 3   │
│ (Guest) │ │ (Guest) │ │ (Guest) │
├─────────┴─┴─────────┴─┴─────────┤
│      Type 1 Hypervisor           │
├──────────────────────────────────┤
│        Physical Hardware         │
└──────────────────────────────────┘
```

代表例:
- **VMware ESXi**: エンタープライズ環境で最も広く使われる。vSphere スイートの一部として高度な管理機能を提供。vMotion によるライブマイグレーション、HA (High Availability)、DRS (Distributed Resource Scheduler) 等の機能を持つ
- **Microsoft Hyper-V**: Windows Server に統合された hypervisor。Windows 10/11 Pro でも利用可能。WSL 2 (Windows Subsystem for Linux 2) の基盤としても使用される
- **Xen**: オープンソースの hypervisor。AWS EC2 の初期基盤として使用された（現在は Nitro System / KVM ベースに移行）。Citrix Hypervisor (旧 XenServer) として商用版も存在
- **KVM (Kernel-based Virtual Machine)**: Linux kernel に統合された hypervisor。/dev/kvm デバイスを通じて仮想化機能を提供。QEMU と組み合わせて使用される。Red Hat, Google Cloud, DigitalOcean 等が採用

特徴:
- ハードウェアに直接アクセスするため**高パフォーマンス**（オーバーヘッド 2-5% 程度）
- データセンターやクラウド環境で使用される
- 管理に専用のツールやインターフェースが必要
- ハードウェア仮想化支援（Intel VT-x / AMD-V）を直接活用

```bash
# KVM が利用可能か確認するコマンド
grep -cE '(vmx|svm)' /proc/cpuinfo
# 出力が 0 より大きければ、ハードウェア仮想化支援が利用可能

# KVM モジュールの確認
lsmod | grep kvm
# 出力例:
# kvm_intel             368640  0
# kvm                  1028096  1 kvm_intel

# /dev/kvm デバイスの確認
ls -la /dev/kvm
# crw-rw----+ 1 root kvm 10, 232 Jan 15 10:00 /dev/kvm
```

#### Type 2 Hypervisor (Hosted Hypervisor)

既存の OS（ホスト OS）上でアプリケーションとして動作する。

```
┌─────────┐ ┌─────────┐
│  VM 1   │ │  VM 2   │
│ (Guest) │ │ (Guest) │
├─────────┴─┴─────────┤
│  Type 2 Hypervisor  │
├──────────────────────┤
│     Host OS          │
├──────────────────────┤
│  Physical Hardware   │
└──────────────────────┘
```

代表例:
- **VirtualBox**: Oracle が開発するオープンソースの hypervisor（GPLv2）
- **VMware Workstation / Fusion**: 商用の高機能 hypervisor
- **Parallels Desktop**: macOS 向けの商用 hypervisor（Apple Silicon 対応が優秀）
- **QEMU**: オープンソースのエミュレータ/仮想化ソフトウェア

特徴:
- 既存の OS 上で動作するため**導入が容易**
- Type 1 と比較するとオーバーヘッドがやや大きい（ホスト OS のスケジューリングを経由するため）
- 開発・テスト環境での利用に適している
- Born2beRoot プロジェクトではこちらを使用する

```
Type 1 と Type 2 のパフォーマンス比較:

Type 1 (ESXi, KVM):
  アプリ → ゲストOS → ハイパーバイザー → ハードウェア
  オーバーヘッド: 2-5%

Type 2 (VirtualBox):
  アプリ → ゲストOS → ハイパーバイザー → ホストOS → ハードウェア
  オーバーヘッド: 10-20%

※ VT-x/AMD-V の利用により、Type 2 でも CPU 命令の
   大部分はハードウェアで直接実行される。
   オーバーヘッドの差は主に I/O 処理に起因する。
```

#### なぜ Born2beRoot で Type 2 を使うのか

42の学校環境では、学生の個人PCまたは学校のMacを使用する。これらのマシンにはすでにOSがインストールされているため、Type 1 Hypervisor をインストールすることは現実的でない。Type 2 Hypervisor を使うことで、既存の環境を壊すことなくLinuxサーバーの構築を学べる。

### 1.4 VirtualBox

Oracle VirtualBox は、オープンソース（GPLv2）の Type 2 Hypervisor である。

主な機能:
- **クロスプラットフォーム**: Windows, macOS, Linux, Solaris で動作
- **スナップショット**: VM の状態を任意の時点で保存・復元。木構造でブランチングも可能
- **仮想ディスク形式**: VDI (VirtualBox Disk Image), VMDK (VMware), VHD (Hyper-V) をサポート
- **ネットワークモード**: NAT, Bridged, Host-only, Internal Network, NAT Network
- **共有フォルダ**: ホストとゲスト間のファイル共有
- **Guest Additions**: ゲスト OS のパフォーマンスと統合を向上（ドライバ、共有クリップボード等）
- **ヘッドレスモード**: GUI なしで VM を起動（VBoxManage コマンドライン）

#### VirtualBox のネットワークモード

| モード | ゲスト→外部 | 外部→ゲスト | ゲスト同士 | ホスト→ゲスト |
|--------|:-----------:|:-----------:|:----------:|:-------------:|
| NAT | OK | Port Forward | NG | Port Forward |
| NAT Network | OK | Port Forward | OK | Port Forward |
| Bridged | OK | OK | OK | OK |
| Host-only | NG | NG | OK | OK |
| Internal | NG | NG | OK | NG |

Born2beRoot では **NAT** + **Port Forwarding** を使用して、ホストからゲストの SSH (port 4242) にアクセスする。

```
各ネットワークモードの詳細:

NAT モード:
┌───────────────────────────────────────────────┐
│ ホスト OS                                      │
│  ┌─────────────────┐                           │
│  │   VirtualBox     │                           │
│  │  ┌───────────┐  │  NAT Engine               │
│  │  │ ゲスト VM │  │  10.0.2.x/24              │
│  │  │ 10.0.2.15 │──┼──→ SNAT ──→ インターネット│
│  │  └───────────┘  │                           │
│  └─────────────────┘                           │
│                                                │
│  各VMが独立したNATネットワークを持つ            │
│  VM間の通信は不可                              │
└───────────────────────────────────────────────┘

Bridged モード:
┌───────────────────────────────────────────────┐
│ 物理ネットワーク (192.168.1.0/24)              │
│                                                │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐    │
│  │ホスト OS │  │ゲスト VM │  │他のPC    │    │
│  │.100      │  │.150      │  │.200      │    │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘    │
│       │             │             │           │
│  ─────┴─────────────┴─────────────┴───────    │
│              物理ネットワーク                   │
│                                                │
│  ゲストVMが物理ネットワーク上に直接接続される   │
│  DHCPでIPアドレスを取得可能                     │
└───────────────────────────────────────────────┘

Host-only モード:
┌───────────────────────────────────────────────┐
│ ホスト OS                                      │
│                                                │
│  vboxnet0 (192.168.56.0/24)                    │
│  ┌──────────┐     ┌──────────┐                │
│  │ホスト    │     │ゲスト VM │                │
│  │.56.1     │─────│.56.101   │                │
│  └──────────┘     └──────────┘                │
│                                                │
│  ホストとゲスト間のみ通信可能                   │
│  インターネットへのアクセスは不可               │
└───────────────────────────────────────────────┘
```

#### NAT モードの内部動作

NAT (Network Address Translation) モードでは、VirtualBox がゲスト VM のためにプライベートネットワーク（通常 10.0.2.0/24）を作成する。ゲスト VM のネットワークトラフィックは、VirtualBox の NAT エンジンによってホスト OS の IP アドレスに変換されて外部に送信される。

```
ゲスト VM (10.0.2.15)
    │
    ▼
VirtualBox NAT Engine
    │  Source IP: 10.0.2.15 → Host IP (例: 192.168.1.100)
    │  Source Port: 12345 → 50000 (動的割り当て)
    ▼
ホスト OS (192.168.1.100)
    │
    ▼
外部ネットワーク / インターネット
```

ポートフォワーディングの設定:
```
ホスト 127.0.0.1:4242 → ゲスト 10.0.2.15:4242
```

これにより、ホストマシンから `ssh user@localhost -p 4242` でゲスト VM に接続できる。

#### VBoxManage コマンドラインツール

VirtualBox はGUIだけでなく、コマンドラインからも操作できる。これはスクリプトによる自動化に有用:

```bash
# VM の一覧表示
VBoxManage list vms
# 出力例: "Born2beRoot" {12345678-abcd-1234-abcd-123456789abc}

# VM の詳細情報
VBoxManage showvminfo "Born2beRoot"

# VM の起動（ヘッドレスモード）
VBoxManage startvm "Born2beRoot" --type headless

# VM の停止
VBoxManage controlvm "Born2beRoot" poweroff

# VM の一時停止・再開
VBoxManage controlvm "Born2beRoot" pause
VBoxManage controlvm "Born2beRoot" resume

# スナップショットの作成
VBoxManage snapshot "Born2beRoot" take "before_config_change"

# スナップショットの復元
VBoxManage snapshot "Born2beRoot" restore "before_config_change"

# ポートフォワーディングの設定
VBoxManage modifyvm "Born2beRoot" --natpf1 "ssh,tcp,,4242,,4242"

# 仮想ディスクのサイズ変更
VBoxManage modifymedium disk "Born2beRoot.vdi" --resize 20480

# VM の仮想ディスクの SHA1 ハッシュ（signature.txt 用）
# ホストOS上で実行:
sha1sum "~/VirtualBox VMs/Born2beRoot/Born2beRoot.vdi"
```

### 1.5 UTM

UTM は macOS (特に Apple Silicon / M1, M2, M3, M4) 向けの仮想化ソフトウェアで、QEMU をバックエンドとして使用する。Apple Silicon Mac では VirtualBox が完全には動作しない（x86エミュレーションが必要になり非常に遅い）ため、UTM が Born2beRoot で許可されている代替となる。

UTM の特徴:
- Apple の Virtualization.framework を利用して ARM64 ゲストをネイティブ速度で実行
- QEMU バックエンドにより x86_64 ゲストのエミュレーションも可能（ただし低速）
- macOS ネイティブの UI を持ち、直感的に操作可能
- Apple Silicon では ARM64 版の Debian を使用することが推奨される

```
UTM のアーキテクチャ:

Apple Silicon Mac (ARM64):
┌───────────────────────────────────────┐
│  ┌─────────────────────────────────┐  │
│  │ UTM Application                 │  │
│  │  ┌──────────────────────────┐   │  │
│  │  │  ARM64 ゲスト            │   │  │
│  │  │  (Debian ARM64)          │   │  │
│  │  │  → ネイティブ速度        │   │  │
│  │  └──────────────────────────┘   │  │
│  │  ┌──────────────────────────┐   │  │
│  │  │  x86_64 ゲスト           │   │  │
│  │  │  (Debian x86_64)         │   │  │
│  │  │  → QEMU エミュレーション │   │  │
│  │  │    (遅い)                │   │  │
│  │  └──────────────────────────┘   │  │
│  └─────────────────────────────────┘  │
│                                        │
│  Virtualization.framework (ARM64)      │
│  QEMU (x86_64 emulation)              │
│                                        │
│  Apple Silicon (M1/M2/M3/M4)          │
└───────────────────────────────────────┘
```

### 1.6 QEMU/KVM

**QEMU (Quick Emulator)** は、オープンソースのマシンエミュレータおよび仮想化ソフトウェアである。

- エミュレーションモード: 異なるアーキテクチャをソフトウェアでエミュレート（遅い、ただし ARM を x86 で動かすなどが可能）
- 仮想化モード: KVM と連携してネイティブに近い速度で仮想化

**KVM (Kernel-based Virtual Machine)** は Linux kernel に組み込まれた仮想化モジュール（kernel 2.6.20 以降）で、Linux を Type 1 Hypervisor として機能させる。

```
┌─────────────────┐ ┌─────────────────┐
│   QEMU Process  │ │   QEMU Process  │
│   (VM 1)        │ │   (VM 2)        │
├─────────────────┴─┴─────────────────┤
│           Linux Kernel + KVM         │
│                                      │
│  /dev/kvm デバイスを通じて           │
│  ハードウェア仮想化支援を利用        │
├──────────────────────────────────────┤
│     Physical Hardware (VT-x/AMD-V)   │
└──────────────────────────────────────┘
```

QEMU/KVM は実際のクラウドインフラ（OpenStack, Proxmox, Google Cloud, DigitalOcean など）で広く使用されている。AWS も最新の Nitro System で KVM ベースの仮想化を採用している。

#### QEMU/KVM の基本コマンド

```bash
# QEMU/KVM で VM を作成（実務参考用）
qemu-img create -f qcow2 debian.qcow2 20G

# VM の起動
qemu-system-x86_64 \
  -enable-kvm \
  -m 2048 \
  -smp 2 \
  -drive file=debian.qcow2,format=qcow2 \
  -cdrom debian-12-amd64-netinst.iso \
  -boot d \
  -net nic -net user,hostfwd=tcp::4242-:4242

# オプションの説明:
# -enable-kvm    : KVM を使用（ハードウェア仮想化）
# -m 2048        : メモリ 2048MB
# -smp 2         : CPU 2コア
# -drive          : 仮想ディスク
# -cdrom          : ISOイメージ
# -boot d         : CD-ROM から起動
# -net             : ネットワーク設定（ポートフォワーディング含む）
```

### 1.7 コンテナ仮想化との違い

Born2beRoot ではVM仮想化を使用するが、現代のインフラではコンテナ仮想化（Docker, Podman）も重要である。両者の違いを理解しておくことは有益:

```
VM 仮想化:                        コンテナ仮想化:
┌──────┐ ┌──────┐                ┌──────┐ ┌──────┐
│App A │ │App B │                │App A │ │App B │
├──────┤ ├──────┤                ├──────┤ ├──────┤
│Bins/ │ │Bins/ │                │Bins/ │ │Bins/ │
│Libs  │ │Libs  │                │Libs  │ │Libs  │
├──────┤ ├──────┤                └──┬───┘ └──┬───┘
│Guest │ │Guest │                   │        │
│ OS   │ │ OS   │                ┌──┴────────┴───┐
├──────┴─┴──────┤                │ Container      │
│  Hypervisor   │                │ Runtime        │
├───────────────┤                │ (Docker/runc)  │
│   Host OS     │                ├────────────────┤
├───────────────┤                │   Host OS      │
│  Hardware     │                │   (共有kernel) │
└───────────────┘                ├────────────────┤
                                 │   Hardware     │
                                 └────────────────┘
```

| 項目 | VM | コンテナ |
|------|----|---------  |
| 分離レベル | 完全な OS 分離 | プロセスレベル分離 |
| オーバーヘッド | 大きい (GB単位のメモリ) | 小さい (MB単位) |
| 起動時間 | 数十秒〜数分 | 数秒以下 |
| カーネル | 各VMに独自カーネル | ホストカーネルを共有 |
| セキュリティ | 高い | VM より低い (カーネル共有) |
| 用途 | 異なるOS実行、高分離性 | アプリケーション配布、マイクロサービス |
| ディスク使用量 | 数GB〜数十GB | 数十MB〜数百MB |
| 密度（1台あたり）| 数十VM | 数百〜数千コンテナ |

```
コンテナの分離メカニズム（Linux の機能を利用）:

┌─────────────────────────────────────────────┐
│  Namespaces (名前空間による分離)             │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐    │
│  │ PID ns   │ │ NET ns   │ │ MNT ns   │    │
│  │ プロセス │ │ ネット   │ │ ファイル │    │
│  │ 空間分離 │ │ ワーク   │ │ システム │    │
│  │          │ │ 分離     │ │ 分離     │    │
│  └──────────┘ └──────────┘ └──────────┘    │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐    │
│  │ UTS ns   │ │ IPC ns   │ │ USER ns  │    │
│  │ ホスト名 │ │ プロセス │ │ UID/GID  │    │
│  │ 分離     │ │ 間通信   │ │ マッピング│   │
│  │          │ │ 分離     │ │          │    │
│  └──────────┘ └──────────┘ └──────────┘    │
├─────────────────────────────────────────────┤
│  cgroups (リソース制限)                      │
│  CPU、メモリ、I/O、ネットワーク帯域を制限    │
├─────────────────────────────────────────────┤
│  Seccomp (システムコールフィルタ)            │
│  コンテナから実行可能なシステムコールを制限   │
├─────────────────────────────────────────────┤
│  AppArmor / SELinux (MAC)                    │
│  コンテナプロセスのアクセス制御              │
└─────────────────────────────────────────────┘
```

Born2beRoot で VM を使う理由は、完全な OS 環境を一から構築する経験が学習目標であるため。

---

## 2. オペレーティングシステム (Operating System)

### 2.1 OS とは何か

オペレーティングシステム (OS) は、ハードウェアとアプリケーションの間で仲介役を果たすソフトウェアである。OS の主な責務は以下の通り:

- **プロセス管理**: プログラムの実行、スケジューリング、プロセス間通信 (IPC)
- **メモリ管理**: 物理メモリの割り当て、仮想メモリ、ページング、スワッピング
- **ファイルシステム**: ディスク上のデータの組織化とアクセス（VFS: Virtual File System を通じて複数のファイルシステムを統一的に扱う）
- **デバイス管理**: ハードウェアデバイスとのインターフェース（ドライバ）
- **ネットワーク**: TCP/IP スタック、ソケット通信、Netfilter
- **セキュリティ**: ユーザー認証、権限管理、暗号化、LSM (Linux Security Modules)

### 2.2 Kernel と Userspace

Linux システムは大きく **Kernel space** と **User space** に分かれる。

```
┌──────────────────────────────────────────────────────────────┐
│                        User Space                            │
│  ┌──────┐ ┌──────┐ ┌──────┐ ┌──────────┐ ┌──────────────┐  │
│  │ bash │ │ sshd │ │ cron │ │ monitoring│ │ systemctl    │  │
│  └──┬───┘ └──┬───┘ └──┬───┘ └──┬───────┘ └──────┬───────┘  │
│     │        │        │        │                 │           │
│  ┌──┴────────┴────────┴────────┴─────────────────┴───────┐  │
│  │              GNU C Library (glibc)                     │  │
│  │        System Call のラッパー関数を提供                │  │
│  └──────────────────────┬────────────────────────────────┘  │
│                          │                                   │
│  ┌───────────────────────┴────────────────────────────────┐  │
│  │              System Call Interface                     │  │
│  │  (約450個のシステムコール: read, write, fork, exec...) │  │
│  └──────────────────────┬────────────────────────────────┘  │
├──────────────────────────┼───────────────────────────────────┤
│  ┌───────────────────────┴────────────────────────────────┐  │
│  │                    Linux Kernel                         │  │
│  │                                                        │  │
│  │  ┌────────────┐ ┌────────────┐ ┌────────────────────┐ │  │
│  │  │  Process   │ │  Memory    │ │       VFS          │ │  │
│  │  │  Scheduler │ │  Manager   │ │ (Virtual File      │ │  │
│  │  │  (CFS)     │ │ (buddy    │ │  System)           │ │  │
│  │  │            │ │  allocator │ │  ext4, tmpfs,      │ │  │
│  │  │  O(log n)  │ │  + SLAB/  │ │  procfs, sysfs,    │ │  │
│  │  │  赤黒木    │ │  SLUB)    │ │  devtmpfs          │ │  │
│  │  └────────────┘ └────────────┘ └────────────────────┘ │  │
│  │  ┌────────────┐ ┌────────────┐ ┌────────────────────┐ │  │
│  │  │  Network   │ │  Device    │ │ Security           │ │  │
│  │  │  Stack     │ │  Drivers   │ │  (LSM Framework)   │ │  │
│  │  │ (TCP/IP,   │ │ (dm-crypt, │ │  AppArmor,         │ │  │
│  │  │  Netfilter,│ │  virtio,   │ │  SELinux,          │ │  │
│  │  │  socket)   │ │  e1000)    │ │  Capabilities      │ │  │
│  │  └────────────┘ └────────────┘ └────────────────────┘ │  │
│  │  ┌────────────┐ ┌────────────┐ ┌────────────────────┐ │  │
│  │  │  IPC       │ │  Block     │ │ Crypto             │ │  │
│  │  │ (pipe,     │ │  Layer     │ │  (AES, SHA,        │ │  │
│  │  │  signal,   │ │ (I/O sched,│ │   dm-crypt,        │ │  │
│  │  │  socket,   │ │  Device    │ │   random)          │ │  │
│  │  │  shm)      │ │  Mapper)   │ │                    │ │  │
│  │  └────────────┘ └────────────┘ └────────────────────┘ │  │
│  └────────────────────────────────────────────────────────┘  │
│                       Kernel Space                           │
├──────────────────────────────────────────────────────────────┤
│                    Physical Hardware                          │
│  ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐ ┌───────────────────┐ │
│  │ CPU  │ │ RAM  │ │ Disk │ │ NIC  │ │ Other Peripherals │ │
│  └──────┘ └──────┘ └──────┘ └──────┘ └───────────────────┘ │
└──────────────────────────────────────────────────────────────┘
```

**Kernel Space**:
- OS の中核部分で、ハードウェアに直接アクセスする特権モード（Ring 0）で動作
- プロセスの作成・終了、メモリの割り当て・解放、デバイスの制御を行う
- System Call を通じて User Space にサービスを提供する
- カーネルのバグは OS 全体のクラッシュ（kernel panic）やセキュリティ脆弱性に直結する

**User Space**:
- アプリケーションが動作する非特権モード（Ring 3）
- Kernel の機能には System Call を通じてのみアクセス可能
- User Space のプログラムがクラッシュしても、他のプロセスや OS には影響しない（分離性）

**System Call の主要な例**:

| カテゴリ | System Call | 説明 | Born2beRoot との関連 |
|---------|------------|------|---------------------|
| プロセス | `fork()` | 現在のプロセスのコピーを作成 | cron が monitoring.sh を起動 |
| プロセス | `exec()` | 現在のプロセスを別のプログラムに置換 | シェルがコマンドを実行 |
| プロセス | `wait()` | 子プロセスの終了を待つ | 親プロセスの管理 |
| プロセス | `exit()` | プロセスを終了 | プログラムの終了処理 |
| プロセス | `clone()` | fork の拡張（スレッド作成にも使用）| スレッド管理 |
| ファイル | `open()` | ファイルを開く | 設定ファイルの読み書き |
| ファイル | `read()` | ファイルからデータを読む | /proc の情報取得 |
| ファイル | `write()` | ファイルにデータを書く | ログの書き込み |
| ファイル | `close()` | ファイルを閉じる | リソースの解放 |
| ファイル | `stat()` | ファイルの属性を取得 | パーミッション確認 |
| ファイル | `ioctl()` | デバイス固有の操作 | ネットワーク設定等 |
| ネットワーク | `socket()` | ネットワークソケットを作成 | SSH サーバーの待ち受け |
| ネットワーク | `bind()` | ソケットにアドレスを割り当て | sshd が port 4242 にバインド |
| ネットワーク | `listen()` | 接続を待ち受ける | sshd の接続待ち |
| ネットワーク | `accept()` | 接続を受け入れる | SSH 接続の確立 |
| ネットワーク | `connect()` | リモートに接続 | クライアントからの接続 |
| メモリ | `mmap()` | メモリマッピング | ファイルのメモリマッピング |
| メモリ | `brk()` | データセグメントの拡張 | ヒープメモリの管理 |
| メモリ | `munmap()` | メモリマッピングの解除 | リソース解放 |

```bash
# システムコールのトレース（実行例）
strace -c ls /etc/
# 出力例:
# % time     seconds  usecs/call     calls    errors syscall
# ------ ----------- ----------- --------- --------- ----------------
#  25.00    0.000125           5        25           openat
#  20.00    0.000100           3        30           close
#  15.00    0.000075           3        25           fstat
#  10.00    0.000050           3        15           read
#   8.00    0.000040           4        10           mmap
#   ...

# 特定のシステムコールのみトレース
strace -e trace=open,read,write cat /etc/hostname
# 出力例:
# openat(AT_FDCWD, "/etc/hostname", O_RDONLY) = 3
# read(3, "kaztakam42\n", 131072)          = 11
# write(1, "kaztakam42\n", 11)             = 11

# ネットワーク関連のシステムコールをトレース
strace -e trace=network ss -tunlp
```

#### CPUの保護リング

x86 アーキテクチャでは、CPU に4つの保護リング（Ring 0-3）がある:

```
    ┌──────────────────────────────────────┐
    │           Ring 3                      │  ← User Space
    │  アプリケーション (bash, sshd, cron)  │     非特権モード
    │                                      │     制限された命令セット
    │  ┌──────────────────────────────┐    │
    │  │         Ring 2               │    │  ← (通常未使用)
    │  │                              │    │     歴史的にはデバイスドライバ用
    │  │  ┌──────────────────────┐    │    │
    │  │  │       Ring 1         │    │    │  ← (通常未使用)
    │  │  │                      │    │    │     歴史的にはOS拡張用
    │  │  │  ┌──────────────┐    │    │    │
    │  │  │  │    Ring 0    │    │    │    │  ← Kernel Space
    │  │  │  │  OS カーネル │    │    │    │     全命令実行可能
    │  │  │  │  全権限      │    │    │    │     ハードウェア直接制御
    │  │  │  └──────────────┘    │    │    │
    │  │  └──────────────────────┘    │    │
    │  └──────────────────────────────┘    │
    └──────────────────────────────────────┘

Ring 3 → Ring 0 への遷移:
  1. ユーザープログラムが syscall 命令を実行
  2. CPU が Ring 3 → Ring 0 に遷移
  3. カーネルがシステムコールを処理
  4. 結果を返して Ring 0 → Ring 3 に戻る

この遷移には「コンテキストスイッチ」のコストが伴う
（レジスタの保存・復元、TLB フラッシュ等）
```

- **Ring 0**: カーネルモード。全ての CPU 命令を実行可能。ハードウェアに直接アクセス可能
- **Ring 3**: ユーザーモード。制限された命令セットのみ実行可能。特権命令を実行しようとすると例外 (General Protection Fault) が発生

仮想化では、ゲスト OS のカーネルは Ring 0 で動作していると「思っている」が、実際にはハイパーバイザーが Ring 0 で動作し、ゲストカーネルは Ring 1 またはハードウェア仮想化支援（VT-x の VMX non-root mode）で動作する。

### 2.3 カーネルの詳細 - 主要サブシステム

Linux カーネルは巨大なソフトウェアであり（約3000万行以上のコード）、複数のサブシステムで構成されている。Born2beRoot に関連する主要なサブシステムを詳しく解説する。

#### 2.3.1 プロセススケジューリング (Process Scheduling)

Linux カーネルは **CFS (Completely Fair Scheduler)** を使用してプロセスのCPU時間を管理する（kernel 2.6.23 以降）。

```
CFS の動作原理:

CFS は「完全に公平な」CPU 時間配分を目指す:

1. 各プロセスに vruntime（仮想実行時間）を割り当て
2. vruntime が最小のプロセスを次に実行
3. 赤黒木（Red-Black Tree）でプロセスを管理

赤黒木の構造:
                    ┌─────┐
                    │P: 50│  ← vruntime 50ms のプロセス
                    │(黒) │
                    └──┬──┘
               ┌───────┴───────┐
            ┌──┴──┐         ┌──┴──┐
            │P: 30│         │P: 70│
            │(赤) │         │(赤) │
            └──┬──┘         └──┬──┘
          ┌────┴────┐     ┌────┴────┐
       ┌──┴──┐  ┌──┴──┐ ┌──┴──┐ ┌──┴──┐
       │P: 20│  │P: 40│ │P: 60│ │P: 80│
       │(黒) │  │(黒) │ │(黒) │ │(黒) │
       └─────┘  └─────┘ └─────┘ └─────┘
          ↑
    次に実行されるプロセス
    (最小 vruntime = 左端のノード)

操作の計算量: O(log n)
  - プロセスの挿入: O(log n)
  - 最小 vruntime のプロセス取得: O(1)（左端キャッシュ）
  - プロセスの削除: O(log n)
```

```bash
# プロセスのスケジューリング情報を確認
cat /proc/self/sched
# 出力例:
# bash (1234, #threads: 1)
# ---
# se.exec_start                      :       1234567.890123
# se.vruntime                        :         12345.678901
# se.sum_exec_runtime                :          5678.901234
# se.nr_migrations                   :                   10
# nr_switches                        :                  100
# nr_voluntary_switches              :                   80
# nr_involuntary_switches            :                   20
# se.load.weight                     :                 1024
# se.avg.load_sum                    :                  500
# policy                             :                    0
# prio                               :                  120

# nice 値の変更（プロセスの優先度調整）
nice -n 10 ./monitoring.sh     # 優先度を下げて実行
renice -n 5 -p 1234            # 既存プロセスの nice 値変更

# スケジューリングポリシーの確認
chrt -p 1234
# 出力例:
# pid 1234's current scheduling policy: SCHED_OTHER
# pid 1234's current scheduling priority: 0
```

スケジューリングポリシーの種類:

| ポリシー | 説明 | 用途 |
|---------|------|------|
| SCHED_OTHER (CFS) | 通常のプロセス | 一般的なアプリケーション |
| SCHED_FIFO | リアルタイム（先入先出） | 低レイテンシ要求 |
| SCHED_RR | リアルタイム（ラウンドロビン） | リアルタイム処理 |
| SCHED_BATCH | バッチ処理向け | バックグラウンドタスク |
| SCHED_IDLE | 最低優先度 | システムアイドル時のタスク |
| SCHED_DEADLINE | デッドラインスケジューリング | 厳密な時間制約 |

#### 2.3.2 メモリ管理 (Memory Management)

Linux のメモリ管理は複数の層で構成される。

```
メモリ管理の全体像:

アプリケーション
    │
    ▼ malloc() / mmap()
┌─────────────────────────────────────────┐
│  仮想アドレス空間 (Virtual Address Space)│
│                                         │
│  プロセスごとに独立した仮想メモリ:       │
│  ┌──────────────────────────────────┐   │
│  │ 0xFFFFFFFF... ┌──────────────┐  │   │
│  │               │  カーネル空間 │  │   │
│  │               │  (共有)      │  │   │
│  │ 0xC0000000    ├──────────────┤  │   │
│  │               │  スタック ↓  │  │   │
│  │               │              │  │   │
│  │               │  (空き領域)  │  │   │
│  │               │              │  │   │
│  │               │  ヒープ ↑   │  │   │
│  │               ├──────────────┤  │   │
│  │               │  BSS         │  │   │
│  │               │  データ      │  │   │
│  │               │  テキスト    │  │   │
│  │ 0x00000000    └──────────────┘  │   │
│  └──────────────────────────────────┘   │
│                                         │
│  MMU (Memory Management Unit)           │
│  ページテーブルで仮想→物理アドレス変換   │
└───────────────────┬─────────────────────┘
                    │
                    ▼
┌─────────────────────────────────────────┐
│  物理メモリ管理                          │
│                                         │
│  Buddy Allocator (バディアロケータ):     │
│  ページ単位 (4KB) での物理メモリ管理     │
│                                         │
│  ┌──┬──┬──┬──┬──┬──┬──┬──┬──┬──┐      │
│  │4K│4K│8K    │16K         │32K│ ... │  │
│  └──┴──┴──────┴────────────┴───┴─────┘  │
│                                         │
│  SLAB/SLUB Allocator:                   │
│  ページ内の小さなオブジェクト管理        │
│  (task_struct, inode, dentry 等の        │
│   カーネルオブジェクト)                  │
└───────────────────┬─────────────────────┘
                    │
                    ▼
┌─────────────────────────────────────────┐
│  Swap (スワップ)                         │
│  物理メモリが不足した場合に              │
│  ページをディスクに退避                  │
│  Born2beRoot: LVM の swap パーティション │
└─────────────────────────────────────────┘
```

```bash
# メモリの詳細情報
cat /proc/meminfo
# 出力例:
# MemTotal:         470000 kB     ← 物理メモリ合計
# MemFree:          150000 kB     ← 未使用メモリ
# MemAvailable:     300000 kB     ← 利用可能メモリ（キャッシュ含む）
# Buffers:           20000 kB     ← ブロックデバイスのバッファ
# Cached:           120000 kB     ← ページキャッシュ
# SwapTotal:        976000 kB     ← スワップ合計
# SwapFree:         976000 kB     ← スワップ空き
# Dirty:                 0 kB     ← ディスクに書き戻すべきページ
# Slab:              30000 kB     ← SLAB アロケータのメモリ

# free コマンド（monitoring.sh で使用）
free -m
# 出力例:
#               total        used        free      shared  buff/cache   available
# Mem:            460         143          98           5         218         300
# Swap:           952           0         952

# OOM Killer のログ確認
dmesg | grep -i "oom\|out of memory"

# プロセスごとのメモリ使用量
cat /proc/1234/status | grep -E "Vm|Rss"
# 出力例:
# VmPeak:     12345 kB    ← 仮想メモリのピーク
# VmSize:     12000 kB    ← 現在の仮想メモリ
# VmRSS:       4000 kB    ← 物理メモリ使用量（Resident Set Size）
# VmSwap:         0 kB    ← スワップ使用量

# SLAB アロケータの情報
cat /proc/slabinfo | head -5
# slabtop コマンドでリアルタイム表示
```

#### 2.3.3 仮想ファイルシステム (VFS: Virtual File System)

VFS は Linux カーネルのファイルシステム抽象化層で、異なるファイルシステムに対して統一的なインターフェースを提供する。

```
VFS のアーキテクチャ:

ユーザープロセス
    │
    ▼ open(), read(), write(), close()
┌─────────────────────────────────────────────────┐
│                   VFS Layer                      │
│                                                  │
│  主要なデータ構造:                               │
│  ┌─────────┐ ┌─────────┐ ┌──────────┐          │
│  │ super_  │ │ inode   │ │ dentry   │          │
│  │ block   │ │         │ │ (ディレク│          │
│  │(FSの    │ │(ファイル│ │ トリエン │          │
│  │ メタ    │ │ のメタ  │ │ トリ)    │          │
│  │ データ) │ │ データ) │ │          │          │
│  └─────────┘ └─────────┘ └──────────┘          │
│  ┌─────────┐                                    │
│  │ file    │                                    │
│  │(オープン│                                    │
│  │ ファイル│                                    │
│  │ テーブル│                                    │
│  │ エントリ│                                    │
│  └─────────┘                                    │
├─────────────────────────────────────────────────┤
│  ┌─────────┐ ┌─────────┐ ┌──────────┐          │
│  │  ext4   │ │  tmpfs  │ │  procfs  │ ...     │
│  └─────────┘ └─────────┘ └──────────┘          │
│  各ファイルシステムが VFS のインターフェースを    │
│  実装する（function pointers による多態性）       │
└─────────────────────────────────────────────────┘

VFS により、以下が可能になる:
  - cat /proc/cpuinfo  (procfs)
  - cat /etc/hostname  (ext4)
  - cat /sys/class/net/enp0s3/address  (sysfs)

  → 全て同じ open()/read()/close() で操作可能
```

Born2beRoot で使用されるファイルシステムの種類:

| ファイルシステム | マウントポイント | 説明 |
|----------------|----------------|------|
| ext4 | /, /home, /var 等 | 主要なデータファイルシステム |
| procfs | /proc | プロセスとカーネル情報（仮想FS） |
| sysfs | /sys | デバイスとドライバ情報（仮想FS） |
| tmpfs | /run, /dev/shm | メモリベースの一時FS |
| devtmpfs | /dev | デバイスファイル（仮想FS） |

### 2.4 Debian

**Debian** は、1993年に Ian Murdock によって創設された、最も歴史ある Linux ディストリビューションの一つである。

歴史と哲学:
- **Debian Social Contract**: フリーソフトウェアへのコミットメント。ユーザーの利益を最優先にする
- **Debian Free Software Guidelines (DFSG)**: ソフトウェアの自由度の基準。これが後にOpen Source Definition の基礎となった
- コミュニティ主導で開発（特定企業による支配がない）
- 安定性と信頼性を最優先

リリースモデル:
- **stable**: 十分にテストされた安定版（サーバー推奨）。リリース後はセキュリティ修正のみ。現在の stable は Debian 12 "Bookworm"
- **testing**: 次の stable に向けたテスト版。パッケージは unstable から一定期間問題がなければ移行される
- **unstable (sid)**: 最新パッケージが含まれる開発版。常に最新だが不安定な場合がある
- **oldstable**: 前のバージョンの stable。一定期間セキュリティサポートが継続される

```
Debian のリリース履歴（コードネームはトイ・ストーリーのキャラクター）:

バージョン  コードネーム   リリース年  カーネル
─────────────────────────────────────────────────
Debian 7    Wheezy        2013        3.2
Debian 8    Jessie        2015        3.16
Debian 9    Stretch       2017        4.9
Debian 10   Buster        2019        4.19
Debian 11   Bullseye      2021        5.10
Debian 12   Bookworm      2023        6.1       ← 現在の stable
Debian 13   Trixie        (予定)      (TBD)     ← 次の stable
sid         sid           (常時)      最新       ← 常に unstable
```

パッケージ管理:
- **dpkg**: 低レベルパッケージマネージャ（.deb ファイルの直接操作）
- **APT (Advanced Package Tool)**: 高レベルパッケージマネージャ（依存関係の自動解決、リポジトリからのダウンロード）
- **aptitude**: APT の高機能なフロントエンド（対話型UIあり、高度な依存関係解決）

```bash
# パッケージ管理コマンドの使い分け

# dpkg（低レベル）
dpkg -i package.deb       # .deb ファイルのインストール
dpkg -l                   # インストール済みパッケージの一覧
dpkg -l | grep ssh        # 特定パッケージの検索
dpkg -L openssh-server    # パッケージのファイル一覧
dpkg -S /usr/sbin/sshd    # ファイルが属するパッケージ
dpkg --configure -a       # 設定途中のパッケージを修復

# apt（高レベル）
apt update                # パッケージリストの更新
apt upgrade               # インストール済みパッケージの更新
apt install ufw           # パッケージのインストール
apt remove ufw            # パッケージの削除
apt purge ufw             # パッケージと設定ファイルの削除
apt autoremove            # 不要な依存パッケージの削除
apt search ssh            # パッケージの検索
apt show openssh-server   # パッケージの詳細情報
apt list --installed      # インストール済みパッケージの一覧

# aptitude（高度な依存関係解決）
aptitude install package  # インストール
aptitude why package      # パッケージが必要な理由
aptitude why-not package  # パッケージが不要な理由
```

Debian が Born2beRoot で推奨される理由:
- 広大なパッケージリポジトリ（約59,000パッケージ以上）
- 安定版は十分にテストされており信頼性が高い
- UFW が利用可能で、ファイアウォール設定が直感的
- AppArmor がデフォルトで有効
- 設定ファイルが直感的で学習しやすい
- Ubuntu の基盤であり、学んだ知識がそのまま Ubuntu にも応用可能

### 2.5 Rocky Linux

**Rocky Linux** は、CentOS 8 の開発方針変更（CentOS Stream への移行）を受けて、CentOS の共同創設者 Gregory Kurtzer によって2021年に始められた、RHEL (Red Hat Enterprise Linux) の完全互換クローンである。

歴史:
- CentOS は長年 RHEL の無償クローンとして広く使われていた（企業のサーバー環境で圧倒的なシェア）
- 2020年12月、Red Hat が CentOS を CentOS Stream に移行すると発表
- CentOS Stream は RHEL の upstream（開発版）となり、安定版ではなくなった
- この方針変更に対する代替として Rocky Linux（CentOS の精神的後継）と AlmaLinux が誕生

パッケージ管理:
- **RPM (Red Hat Package Manager)**: 低レベルパッケージマネージャ
- **DNF (Dandified YUM)**: 高レベルパッケージマネージャ（YUM の後継）
- パッケージ形式は `.rpm`

セキュリティ:
- **SELinux** がデフォルトで有効（Debian の AppArmor に相当するが、より強力で複雑）
- **firewalld** がデフォルトのファイアウォール（Debian の UFW に相当するが、zone ベース管理）

### 2.6 Debian vs Rocky Linux 比較

| 項目 | Debian | Rocky Linux |
|------|--------|-------------|
| ベース | 独自（Debian プロジェクト） | RHEL クローン |
| パッケージ形式 | .deb | .rpm |
| パッケージマネージャ | apt / aptitude / dpkg | dnf / rpm |
| デフォルト Firewall | UFW (iptables/nftables) | firewalld (nftables) |
| セキュリティモジュール | AppArmor | SELinux |
| init システム | systemd | systemd |
| リリースサイクル | 約2年ごと | RHEL に追従（約3年ごと） |
| コミュニティ | 完全コミュニティ主導 | コミュニティ主導 (RHEL 互換) |
| 企業利用 | Ubuntu Server 経由で多い | RHEL/CentOS の代替として多い |
| 設定ファイルの場所 | Debian 固有のパス | Red Hat 固有のパス |
| サポート期間 | 約5年 (LTS) | 約10年 (RHEL に準拠) |

---

## 3. ネットワークスタック (Network Stack)

### 3.1 TCP/IP 4層モデルの詳細

Born2beRoot ではネットワーク設定（SSH、UFW、NAT）を行うため、TCP/IP の深い理解が不可欠である。

```
OSI 7層モデルと TCP/IP 4層モデルの対応:

OSI 7層モデル          TCP/IP 4層モデル        Born2beRoot での関連
─────────────────────────────────────────────────────────────────
Layer 7: Application  ┐                        SSH プロトコル
Layer 6: Presentation ├→ Application Layer     SSL/TLS 暗号化
Layer 5: Session      ┘                        セッション管理

Layer 4: Transport    → Transport Layer        TCP (port 4242)
                                                3-way handshake

Layer 3: Network      → Internet Layer         IP アドレッシング
                                                ルーティング
                                                ICMP (ping)

Layer 2: Data Link    ┐→ Network Interface     MAC アドレス
Layer 1: Physical     ┘   Layer                 Ethernet フレーム
                                                物理接続
```

```
パケットのカプセル化の詳細:

アプリケーションデータ: "SSH-2.0-OpenSSH_9.2p1 Debian-2"
     │
     ▼ (Layer 4: TCP ヘッダーを追加)
┌────────────────────────────────────────────────┐
│ TCP Header (20-60 bytes)                       │
│ ┌──────────────────────────────────────────┐   │
│ │ Source Port:      50000                  │   │
│ │ Destination Port: 4242                   │   │
│ │ Sequence Number:  1234567890             │   │
│ │ Acknowledgment:   0987654321             │   │
│ │ Flags:            SYN=0, ACK=1, PSH=1   │   │
│ │ Window Size:      65535                  │   │
│ │ Checksum:         0x1234                 │   │
│ └──────────────────────────────────────────┘   │
│ + Application Data                             │
└────────────────────────────────────────────────┘
     │
     ▼ (Layer 3: IP ヘッダーを追加)
┌────────────────────────────────────────────────┐
│ IP Header (20-60 bytes)                        │
│ ┌──────────────────────────────────────────┐   │
│ │ Version:          4 (IPv4)               │   │
│ │ Header Length:    20 bytes               │   │
│ │ Total Length:     512 bytes              │   │
│ │ TTL:              64                     │   │
│ │ Protocol:         6 (TCP)               │   │
│ │ Source IP:        10.0.2.15             │   │
│ │ Destination IP:   93.184.216.34        │   │
│ │ Header Checksum:  0x5678               │   │
│ └──────────────────────────────────────────┘   │
│ + TCP Header + Application Data                │
└────────────────────────────────────────────────┘
     │
     ▼ (Layer 2: Ethernet ヘッダーを追加)
┌────────────────────────────────────────────────┐
│ Ethernet Frame                                  │
│ ┌──────────────────────────────────────────┐   │
│ │ Dest MAC:   08:00:27:xx:xx:xx            │   │
│ │ Src MAC:    08:00:27:yy:yy:yy            │   │
│ │ EtherType:  0x0800 (IPv4)                │   │
│ └──────────────────────────────────────────┘   │
│ + IP Header + TCP Header + Application Data    │
│ ┌──────────────────────────────────────────┐   │
│ │ FCS (Frame Check Sequence): CRC-32       │   │
│ └──────────────────────────────────────────┘   │
└────────────────────────────────────────────────┘
```

### 3.2 TCP の詳細 - 3ウェイハンドシェイク

TCP (Transmission Control Protocol) は**コネクション指向**のプロトコルで、信頼性の高いデータ転送を保証する。SSH は TCP 上で動作する。

#### 3ウェイハンドシェイク（接続確立）の詳細

```
Client (10.0.2.1)                              Server (10.0.2.15:4242)
    │                                              │
    │  [1] SYN                                     │
    │  ┌─────────────────────────────────────┐     │
    │  │ SYN=1, ACK=0                        │     │
    │  │ Seq=1000 (ISN: Initial Seq Number)  │     │
    │  │ Window=65535                         │     │
    │  │ MSS=1460 (Maximum Segment Size)     │     │
    │  └──────────────────────────────────────│────→│
    │                                              │
    │  状態: SYN_SENT                    状態: SYN_RECEIVED
    │                                              │
    │  [2] SYN-ACK                                 │
    │     ┌────────────────────────────────────┐   │
    │     │ SYN=1, ACK=1                       │   │
    │     │ Seq=5000 (Server ISN)              │   │
    │     │ Ack=1001 (Client ISN + 1)          │   │
    │     │ Window=65535                        │   │
    │     │ MSS=1460                            │   │
    │←────│────────────────────────────────────┘   │
    │                                              │
    │  [3] ACK                                     │
    │  ┌──────────────────────────────────────┐    │
    │  │ SYN=0, ACK=1                         │    │
    │  │ Seq=1001                              │    │
    │  │ Ack=5001 (Server ISN + 1)            │    │
    │  └──────────────────────────────────────│───→│
    │                                              │
    │  状態: ESTABLISHED                 状態: ESTABLISHED
    │                                              │
    │  ←───── 暗号化された SSH セッション ────→     │
    │                                              │
    │  [4] 接続終了 (4-way termination)            │
    │  ┌─────────────────────────────────────┐     │
    │  │ FIN=1, ACK=1, Seq=2000             │     │
    │  └─────────────────────────────────────│────→│
    │     ┌────────────────────────────────────┐   │
    │     │ ACK=1, Seq=6000, Ack=2001         │   │
    │←────│────────────────────────────────────┘   │
    │     ┌────────────────────────────────────┐   │
    │     │ FIN=1, ACK=1, Seq=6001            │   │
    │←────│────────────────────────────────────┘   │
    │  ┌─────────────────────────────────────┐     │
    │  │ ACK=1, Seq=2001, Ack=6002          │     │
    │  └─────────────────────────────────────│────→│
    │                                              │
    │  状態: TIME_WAIT → CLOSED       状態: CLOSED │
```

#### TCP の状態遷移図

```
                    ┌──────────┐
                    │  CLOSED  │
                    └─────┬────┘
              ┌───────────┴───────────┐
        passive open              active open
        (listen)                  (connect)
              │                       │
              ▼                       ▼
        ┌──────────┐           ┌──────────┐
        │  LISTEN  │           │ SYN_SENT │
        └─────┬────┘           └─────┬────┘
         rcv SYN                rcv SYN-ACK
         snd SYN-ACK            snd ACK
              │                       │
              ▼                       ▼
        ┌──────────────┐      ┌──────────────┐
        │ SYN_RECEIVED │      │ ESTABLISHED  │
        └──────┬───────┘      └──────────────┘
          rcv ACK                     │
              │                  close / FIN
              ▼                       │
        ┌──────────────┐              │
        │ ESTABLISHED  │              ▼
        └──────────────┘        ┌──────────┐
                                │ FIN_WAIT │
                                └──────────┘
```

```bash
# TCP 接続の状態を確認するコマンド
ss -tan
# 出力例:
# State      Recv-Q Send-Q Local Address:Port  Peer Address:Port
# LISTEN     0      128    0.0.0.0:4242         0.0.0.0:*
# ESTAB      0      0      10.0.2.15:4242       10.0.2.2:50001
# TIME-WAIT  0      0      10.0.2.15:4242       10.0.2.2:49999

# TCP 接続数のカウント（monitoring.sh で使用）
ss -t state established | wc -l

# 各状態の接続数
ss -s
# 出力例:
# Total: 150
# TCP:   10 (estab 2, closed 0, orphaned 0, timewait 0)
# Transport Total     IP        IPv6
# RAW       0         0         0
# UDP       4         2         2
# TCP       10        5         5
# INET      14        7         7
# FRAG      0         0         0
```

#### TCP の信頼性保証メカニズム

TCP が信頼性を保証する仕組み:

| メカニズム | 説明 | 動作 |
|-----------|------|------|
| シーケンス番号 | データの順序を管理 | 各バイトに番号を付与 |
| 確認応答 (ACK) | 受信確認 | 受信側が次に期待するバイト番号を返す |
| 再送制御 | パケット損失への対処 | タイムアウトで再送 |
| フロー制御 | 受信側の処理能力に合わせる | ウィンドウサイズで調整 |
| 輻輳制御 | ネットワークの混雑に対処 | Slow Start, Congestion Avoidance |
| チェックサム | データ破損の検出 | ヘッダーとデータの整合性確認 |

### 3.3 UDP の詳細

UDP (User Datagram Protocol) は**コネクションレス**のプロトコル。高速だが信頼性の保証がない。

```
UDP ヘッダー構造（8 bytes のみ）:
┌────────────────┬────────────────┐
│ Source Port    │ Dest Port      │
│ (16 bits)      │ (16 bits)      │
├────────────────┼────────────────┤
│ Length         │ Checksum       │
│ (16 bits)      │ (16 bits)      │
└────────────────┴────────────────┘

TCP ヘッダー（20-60 bytes）と比較して非常にシンプル。
→ オーバーヘッドが小さく、高速。

使用例:
  DNS (port 53):  名前解決（小さなクエリ、高速応答が重要）
  DHCP (port 67/68): IP アドレス割り当て
  NTP (port 123): 時刻同期
  SNMP (port 161): ネットワーク監視
```

### 3.4 ソケット (Socket)

ソケットは、アプリケーションがネットワーク通信を行うためのインターフェースである。SSH サーバー (sshd) はソケットを使って接続を待ち受ける。

```
sshd のソケット動作:

sshd (サーバー側):
  1. socket()    → ソケット作成 (fd=3)
  2. bind()      → 0.0.0.0:4242 にバインド
  3. listen()    → 接続待ちキューを作成 (backlog=128)
  4. accept()    → 接続を受け入れ (新しい fd=4 を返す)
  5. fork()      → 子プロセスを作成して接続を処理
  6. close()     → 親プロセスは fd=4 を閉じる
  7. → 4. に戻る（次の接続を待つ）

ssh (クライアント側):
  1. socket()    → ソケット作成 (fd=3)
  2. connect()   → サーバーの IP:4242 に接続
  3. read/write  → データの送受信
  4. close()     → 接続を閉じる

┌──────────────┐                    ┌──────────────┐
│  ssh client  │                    │    sshd      │
│              │                    │              │
│  socket()    │                    │  socket()    │
│  connect()───┼──── TCP 接続 ──→  │  bind()      │
│              │                    │  listen()    │
│  write() ────┼──── データ ────→  │  accept()    │
│  read() ←────┼──── データ ←───── │  read()      │
│              │                    │  write()     │
│  close()     │                    │  close()     │
└──────────────┘                    └──────────────┘
```

```bash
# ソケットの情報を確認
ss -tunlp
# 出力例:
# Netid  State    Recv-Q  Send-Q   Local Address:Port   Peer Address:Port  Process
# tcp    LISTEN   0       128      0.0.0.0:4242          0.0.0.0:*          users:(("sshd",pid=500,fd=3))

# 各フィールドの意味:
# Netid: プロトコル (tcp/udp)
# State: ソケットの状態 (LISTEN = 接続待ち)
# Recv-Q: 受信キューのバイト数
# Send-Q: 送信キューのバイト数 (LISTEN時は backlog)
# Local Address:Port: バインドしているアドレスとポート
# Peer Address:Port: 接続先（LISTEN時は *）
# Process: プロセス情報
```

### 3.5 IP アドレスとサブネットマスク

#### IP アドレスの構造

**IPv4 アドレス**は 32 ビットの数値で、ドット区切り10進表記で表現される:

```
192.168.1.100 の2進数表現:

  192      .  168      .  1        .  100
11000000   . 10101000  . 00000001  . 01100100

サブネットマスク 255.255.255.0 (/24):
11111111   . 11111111  . 11111111  . 00000000
└─────── ネットワーク部 ─────────┘  └ホスト部┘

ネットワークアドレス（AND演算）:
  11000000.10101000.00000001.01100100  (192.168.1.100)
& 11111111.11111111.11111111.00000000  (255.255.255.0)
= 11000000.10101000.00000001.00000000  (192.168.1.0)

ブロードキャストアドレス（ホスト部を全て1）:
  11000000.10101000.00000001.11111111  (192.168.1.255)

使用可能なホストアドレス:
  192.168.1.1 ～ 192.168.1.254 (254台)
```

#### CIDR (Classless Inter-Domain Routing) 表記

```
サブネットマスクの例:

CIDR    サブネットマスク          ホスト数    用途
─────────────────────────────────────────────────────
/8      255.0.0.0               16,777,214  大規模ネットワーク
/16     255.255.0.0             65,534      中規模ネットワーク
/24     255.255.255.0           254         小規模ネットワーク
/25     255.255.255.128         126         サブネット分割
/26     255.255.255.192         62          小サブネット
/27     255.255.255.224         30          小サブネット
/28     255.255.255.240         14          極小サブネット
/30     255.255.255.252         2           ポイントツーポイント
/32     255.255.255.255         1           ホストルート

VirtualBox NAT:
  10.0.2.0/24  → ゲスト VM に 10.0.2.15 が割り当てられる
  ゲートウェイ: 10.0.2.2
  DNS: 10.0.2.3
```

プライベート IP アドレスの範囲（RFC 1918）:
```
10.0.0.0/8        (10.0.0.0 - 10.255.255.255)     約1677万アドレス
172.16.0.0/12     (172.16.0.0 - 172.31.255.255)    約104万アドレス
192.168.0.0/16    (192.168.0.0 - 192.168.255.255)  約65000アドレス
```

### 3.6 DNS (Domain Name System)

DNS はドメイン名を IP アドレスに変換するシステムである。

```
DNS クエリの流れ（apt update 時の名前解決）:

ゲスト VM                  DNS リゾルバ              ルートDNS     .org DNS    debian DNS
(10.0.2.15)                (10.0.2.3)
    │                          │                       │            │           │
    │ "deb.debian.org の      │                       │            │           │
    │  IP アドレスは？"        │                       │            │           │
    │──────────────────────→  │                       │            │           │
    │                          │ "org の NS は？"      │            │           │
    │                          │─────────────────────→│            │           │
    │                          │←─ ns1.org ───────────│            │           │
    │                          │                       │            │           │
    │                          │ "debian.org の NS は？"            │           │
    │                          │──────────────────────────────────→│           │
    │                          │←─ ns1.debian.org ────────────────│           │
    │                          │                       │            │           │
    │                          │ "deb.debian.org の IP は？"                   │
    │                          │──────────────────────────────────────────────→│
    │                          │←─ 199.232.182.132 ──────────────────────────│
    │                          │                       │            │           │
    │←── 199.232.182.132 ─────│                       │            │           │
    │                          │                       │            │           │
```

```bash
# DNS 関連の設定ファイル
cat /etc/resolv.conf
# 出力例:
# nameserver 10.0.2.3

# DNS の確認コマンド
nslookup deb.debian.org
# 出力例:
# Server:		10.0.2.3
# Address:	10.0.2.3#53
#
# Non-authoritative answer:
# deb.debian.org	canonical name = debian.map.fastlydns.net.
# Name:	debian.map.fastlydns.net
# Address: 199.232.182.132

# dig コマンドでより詳細な情報
dig deb.debian.org
# ;; ANSWER SECTION:
# deb.debian.org.	300	IN	CNAME	debian.map.fastlydns.net.
# debian.map.fastlydns.net. 30	IN	A	199.232.182.132

# /etc/hosts ファイル（ローカルの名前解決）
cat /etc/hosts
# 127.0.0.1    localhost
# 127.0.1.1    kaztakam42
```

### 3.7 ルーティング (Routing)

```bash
# ルーティングテーブルの確認
ip route show
# 出力例:
# default via 10.0.2.2 dev enp0s3
# 10.0.2.0/24 dev enp0s3 proto kernel scope link src 10.0.2.15

# ルーティングの解説:
# default via 10.0.2.2 dev enp0s3
#   → デフォルトゲートウェイ: 10.0.2.2 (VirtualBox NAT ルーター)
#   → 宛先が他のルールにマッチしない場合、ここに転送
#
# 10.0.2.0/24 dev enp0s3 proto kernel scope link src 10.0.2.15
#   → 10.0.2.0/24 宛のパケットは直接 enp0s3 から送信
#   → 送信元 IP: 10.0.2.15

# パケットの経路を追跡
traceroute 8.8.8.8
# 出力例:
#  1  10.0.2.2   0.5 ms  ← VirtualBox NAT ゲートウェイ
#  2  192.168.1.1  1.0 ms ← ホストのルーター
#  3  ...                  ← ISP のルーター
#  n  8.8.8.8    10.0 ms  ← Google DNS
```

```
パケットルーティングの流れ:

ゲスト VM (10.0.2.15) が 8.8.8.8 にパケットを送信:

1. カーネルがルーティングテーブルを検索
   - 8.8.8.8 は 10.0.2.0/24 にマッチしない
   - default ルートにマッチ → ゲートウェイ 10.0.2.2 へ

2. ARP でゲートウェイの MAC アドレスを取得
   - ARP request: "10.0.2.2 の MAC アドレスは？"
   - ARP reply: "08:00:27:xx:xx:xx"

3. Ethernet フレームを構築して送信
   - Dst MAC: 08:00:27:xx:xx:xx (ゲートウェイ)
   - Src MAC: 08:00:27:yy:yy:yy (自分)
   - IP dst: 8.8.8.8
   - IP src: 10.0.2.15

4. VirtualBox NAT エンジンが SNAT を実行
   - IP src: 10.0.2.15 → ホスト IP に変換
```

### 3.8 ARP (Address Resolution Protocol)

ARP は IP アドレスから MAC アドレスを解決するプロトコル:

```bash
# ARP テーブルの確認
ip neigh show
# 出力例:
# 10.0.2.2 dev enp0s3 lladdr 52:54:00:12:35:02 REACHABLE
# 10.0.2.3 dev enp0s3 lladdr 52:54:00:12:35:03 STALE

# ARP の動作:
# 1. IP パケットを送信する前に、宛先の MAC アドレスが必要
# 2. ARP テーブルに MAC アドレスがない場合:
#    - ARP Request をブロードキャスト送信
#    - 対象ホストが ARP Reply で自身の MAC アドレスを返す
# 3. 取得した MAC アドレスを ARP テーブルにキャッシュ
```

---

## 4. LVM (Logical Volume Manager)

### 4.1 LVM とは何か

LVM は、Linux における論理ボリューム管理システムである。物理ディスクを抽象化し、柔軟なストレージ管理を可能にする。

従来のパーティション管理の問題点:
- パーティションのサイズ変更が非常に困難（オフラインでの操作、データ移動が必要）
- ディスクの追加が既存のファイルシステムに統合しづらい
- パーティションは物理ディスクの境界に縛られる

LVM はこれらの問題を解決し、**物理ストレージの上に論理的な抽象レイヤー**を提供する。

### 4.2 LVM の構造

```
Physical Disks
┌──────────────────┐ ┌──────────────────┐
│    /dev/sda      │ │    /dev/sdb      │
│     500GB        │ │     500GB        │
│                  │ │                  │
│  ┌────────────┐  │ │  ┌────────────┐  │
│  │ Partition  │  │ │  │ Partition  │  │
│  │  sda1      │  │ │  │  sdb1      │  │
│  │  (boot)    │  │ │  │            │  │
│  ├────────────┤  │ │  │            │  │
│  │ Partition  │  │ │  │            │  │
│  │  sda2      │  │ │  │            │  │
│  │  (LVM PV)  │  │ │  │  (LVM PV)  │  │
│  └────────────┘  │ │  └────────────┘  │
└────────┬─────────┘ └────────┬─────────┘
         │                    │
         ▼                    ▼
Physical Volumes (PV)
┌──────────────────┐ ┌──────────────────┐
│  PV: /dev/sda2   │ │  PV: /dev/sdb1   │
│  498GB           │ │  500GB           │
│                  │ │                  │
│  PE 配列:        │ │  PE 配列:        │
│  [PE0][PE1]...   │ │  [PE0][PE1]...   │
│  [PE2][PE3]...   │ │  [PE2][PE3]...   │
│  各PE = 4MB      │ │  各PE = 4MB      │
│  合計: ~127,488  │ │  合計: ~128,000  │
│  PEs             │ │  PEs             │
└────────┬─────────┘ └────────┬─────────┘
         │                    │
         └────────┬───────────┘
                  ▼
Volume Group (VG)
┌──────────────────────────────────────┐
│  VG: "LVMGroup"                      │
│  Total: 998GB (~255,488 PEs)         │
│  Free:  970GB (~248,320 PEs)         │
│                                      │
│  PE Pool:                            │
│  ┌──┬──┬──┬──┬──┬──┬──┬──┬──┬──┐   │
│  │PE│PE│PE│PE│PE│PE│PE│PE│PE│PE│...│
│  └──┴──┴──┴──┴──┴──┴──┴──┴──┴──┘   │
│  (PV1 の PE と PV2 の PE が統合)     │
└───┬────┬────┬────┬────┬────┬────┬──┘
    │    │    │    │    │    │    │
    ▼    ▼    ▼    ▼    ▼    ▼    ▼
Logical Volumes (LV)
┌──────┐┌──────┐┌──────┐┌──────┐┌──────┐┌──────┐┌──────┐
│ root ││ swap ││ home ││ var  ││ srv  ││ tmp  ││var-  │
│ 10G  ││ 2.3G ││  5G  ││  3G  ││  3G  ││  3G  ││log   │
│      ││      ││      ││      ││      ││      ││  4G  │
│ext4  ││swap  ││ext4  ││ext4  ││ext4  ││ext4  ││ext4  │
│  /   ││[SWAP]││/home ││/var  ││/srv  ││/tmp  ││/var/ │
│      ││      ││      ││      ││      ││      ││ log  │
└──────┘└──────┘└──────┘└──────┘└──────┘└──────┘└──────┘
```

### 4.3 LVM の内部構造 - Physical Extent (PE) と Logical Extent (LE)

LVM の内部では、ストレージは **Extent** と呼ばれる固定サイズのブロックに分割される。これが LVM の柔軟性の鍵である。

**Physical Extent (PE)**: PV を構成する固定サイズのブロック（デフォルト 4MB）
**Logical Extent (LE)**: LV を構成する固定サイズのブロック（PE と同サイズ）

```
PV1 の PE:                    PV2 の PE:
┌───┬───┬───┬───┬───┬───┐   ┌───┬───┬───┬───┬───┬───┐
│PE0│PE1│PE2│PE3│PE4│PE5│   │PE0│PE1│PE2│PE3│PE4│PE5│
└─┬─┴─┬─┴─┬─┴───┴───┴───┘   └─┬─┴─┬─┴───┴───┴───┴───┘
  │   │   │                    │   │
  ▼   ▼   ▼                    ▼   ▼
LV "root" の LE:              LV "home" の LE:
┌───┬───┬───┐                 ┌───┬───┐
│LE0│LE1│LE2│                 │LE0│LE1│
└───┴───┴───┘                 └───┴───┘

PE→LE のマッピング:
  root: PV1:PE0→LE0, PV1:PE1→LE1, PV1:PE2→LE2
  home: PV2:PE0→LE0, PV2:PE1→LE1

LV は複数の PV にまたがることも可能:
LV "large" の場合:
  PV1:PE3→LE0, PV1:PE4→LE1, PV2:PE2→LE2, PV2:PE3→LE3
  ┌───┬───┬───┬───┐
  │LE0│LE1│LE2│LE3│
  │PV1│PV1│PV2│PV2│  ← 2つの PV にまたがっている
  └───┴───┴───┴───┘
```

この PE/LE のマッピングにより:
- LV は複数の PV にまたがることができる（ストライピング）
- LV のサイズ変更は PE の追加/削除で行われる（高速）
- PV 間でデータを移動できる（pvmove コマンド）

#### LVM メタデータの構造

```
PV の内部レイアウト:

┌─────────────────────────────────────────────┐
│ PV Label (512 bytes)                         │
│  - UUID                                      │
│  - Device size                               │
│  - Offset to metadata area                   │
├─────────────────────────────────────────────┤
│ Metadata Area (通常 1MB)                     │
│  - VG name, UUID                             │
│  - PV list                                   │
│  - LV list                                   │
│  - PE → LE マッピング                        │
│  - テキスト形式で保存（人間が読める）        │
├─────────────────────────────────────────────┤
│ PE 0 (4MB)                                   │
├─────────────────────────────────────────────┤
│ PE 1 (4MB)                                   │
├─────────────────────────────────────────────┤
│ PE 2 (4MB)                                   │
├─────────────────────────────────────────────┤
│ ...                                          │
└─────────────────────────────────────────────┘
```

### 4.4 LVM コマンドの詳細

```bash
# === Physical Volume (PV) 操作 ===

# PV の作成
sudo pvcreate /dev/sda2
# 出力: Physical volume "/dev/sda2" successfully created.

# PV の詳細表示
sudo pvdisplay
# 出力例:
#   --- Physical volume ---
#   PV Name               /dev/sda2
#   VG Name               LVMGroup
#   PV Size               18.52 GiB / not usable 0
#   Allocatable           yes
#   PE Size               4.00 MiB          ← PE のサイズ
#   Total PE              4741              ← 全 PE 数
#   Free PE               2000              ← 空き PE 数
#   Allocated PE          2741              ← 使用中 PE 数
#   PV UUID               xxxxx-xxxx-xxxx-xxxx-xxxx-xxxx-xxxxxx

# PV の簡易表示
sudo pvs
# 出力例:
#   PV         VG       Fmt  Attr PSize   PFree
#   /dev/sda2  LVMGroup lvm2 a--  18.52g  7.83g

# === Volume Group (VG) 操作 ===

# VG の作成
sudo vgcreate LVMGroup /dev/sda2

# VG の詳細表示
sudo vgdisplay
# 出力例:
#   --- Volume group ---
#   VG Name               LVMGroup
#   System ID
#   Format                lvm2
#   VG Access             read/write
#   VG Status             resizable
#   VG Size               18.52 GiB
#   PE Size               4.00 MiB
#   Total PE              4741
#   Alloc PE / Size       2741 / 10.71 GiB
#   Free  PE / Size       2000 / 7.81 GiB
#   VG UUID               xxxxx-xxxx-xxxx-xxxx-xxxx-xxxx-xxxxxx

# VG にディスクを追加（拡張）
sudo vgextend LVMGroup /dev/sdb1

# === Logical Volume (LV) 操作 ===

# LV の作成
sudo lvcreate -L 10G -n root LVMGroup
sudo lvcreate -L 2.3G -n swap LVMGroup
sudo lvcreate -L 5G -n home LVMGroup

# LV の詳細表示
sudo lvdisplay
# 出力例:
#   --- Logical volume ---
#   LV Path                /dev/LVMGroup/root
#   LV Name                root
#   VG Name                LVMGroup
#   LV UUID                xxxxx-xxxx-xxxx-xxxx-xxxx-xxxx-xxxxxx
#   LV Write Access        read/write
#   LV Status              available
#   LV Size                10.00 GiB
#   Current LE             2560          ← LE 数 (2560 x 4MB = 10GB)
#   Segments               1
#   Allocation             inherit

# LV の簡易表示
sudo lvs
# 出力例:
#   LV      VG       Attr       LSize  Pool Origin Data%  Meta%
#   home    LVMGroup -wi-ao----  5.00g
#   root    LVMGroup -wi-ao---- 10.00g
#   swap    LVMGroup -wi-ao----  2.30g
#   var     LVMGroup -wi-ao----  3.00g

# LV のサイズ拡張（ファイルシステムも同時に拡張）
sudo lvextend -L +5G /dev/LVMGroup/home
sudo resize2fs /dev/LVMGroup/home
# または一括:
sudo lvextend -L +5G --resizefs /dev/LVMGroup/home

# LV の縮小（注意: ext4 をアンマウントしてから）
sudo umount /home
sudo e2fsck -f /dev/LVMGroup/home
sudo resize2fs /dev/LVMGroup/home 3G
sudo lvreduce -L 3G /dev/LVMGroup/home
sudo mount /home
```

### 4.5 Born2beRoot でのパーティション構成

必須パーティション構成（最低限 2 つの暗号化パーティション + LVM）:

```
/dev/sda
├── sda1 (500MB)      → /boot (暗号化なし)
└── sda2 (残り全部)   → 暗号化パーティション
    └── sda2_crypt    → LUKS で暗号化
        └── LVMGroup  → Volume Group
            ├── root  → / (ルート)
            └── swap  → [SWAP]
```

Bonus パーティション構成:

```
/dev/sda
├── sda1 (500MB)          → /boot
└── sda2 (残り全部)
    └── sda5
        └── sda5_crypt
            └── LVMGroup
                ├── root     → /
                ├── swap     → [SWAP]
                ├── home     → /home
                ├── var      → /var
                ├── srv      → /srv
                ├── tmp      → /tmp
                └── var--log → /var/log
```

---

## 5. ディスク暗号化 (LUKS / dm-crypt)

### 5.1 ディスク暗号化とは何か

ディスク暗号化は、ストレージデバイス上のデータを暗号化することで、物理的なアクセスがあってもデータを保護する技術である。ディスクが盗まれたり、不正にアクセスされた場合でも、暗号鍵なしにはデータを読み取れない。

### 5.2 LUKS (Linux Unified Key Setup)

**LUKS** は Linux における標準的なディスク暗号化仕様である。

特徴:
- 複数のパスフレーズ（最大8つのキースロット）をサポート
- ヘッダーにメタデータを格納し、暗号化方式やキースロットを管理
- **dm-crypt** カーネルモジュールを使用して暗号化/復号を行う
- AES-256-XTS が標準的な暗号化アルゴリズム

#### LUKS ヘッダーの構造

```
┌──────────────────────────────────────────────────────┐
│                    LUKS Header                        │
│  ┌─────────────────────────────────────────────────┐ │
│  │ Magic Number: "LUKS\xba\xbe"                    │ │
│  │ Version: 2 (LUKS2)                              │ │
│  │ Cipher Name: aes                                │ │
│  │ Cipher Mode: xts-plain64                        │ │
│  │ Hash Spec: sha256                               │ │
│  │ Key Bytes: 64 (= 512 bits / 8)                 │ │
│  │   → AES-256-XTS は 2 つの 256-bit 鍵を使用     │ │
│  │ Master Key Digest: (ハッシュ)                   │ │
│  │ Master Key Salt: (ランダム)                     │ │
│  │ Master Key Iterations: (PBKDF2 反復回数)        │ │
│  ├─────────────────────────────────────────────────┤ │
│  │ Key Slot 0: [Active]                            │ │
│  │   Iterations: 2000000                           │ │
│  │   Salt: (ランダム 32 bytes)                     │ │
│  │   Key Material Offset: sector N                 │ │
│  │   AF Stripes: 4000                              │ │
│  │                                                  │ │
│  │   復号の流れ:                                   │ │
│  │   パスフレーズ                                   │ │
│  │     ↓ PBKDF2 (パスフレーズ + Salt, 反復回数)    │ │
│  │   派生鍵 (Derived Key)                          │ │
│  │     ↓ AES 復号                                  │ │
│  │   Split Key (AF Stripes で分割された鍵)         │ │
│  │     ↓ Anti-Forensic Merge                       │ │
│  │   Master Key (マスター鍵)                       │ │
│  │     ↓ ダイジェスト照合                          │ │
│  │   Master Key が正しいことを確認                  │ │
│  ├─────────────────────────────────────────────────┤ │
│  │ Key Slot 1: [Inactive]                          │ │
│  │ Key Slot 2: [Inactive]                          │ │
│  │ ...                                              │ │
│  │ Key Slot 7: [Inactive]                          │ │
│  └─────────────────────────────────────────────────┘ │
├──────────────────────────────────────────────────────┤
│           Encrypted Data Area                        │
│  (AES-256-XTS で暗号化されたデータ)                 │
│                                                      │
│  各セクター（512 bytes）を独立に暗号化:              │
│  ┌─────────┬─────────┬─────────┬─────────┐          │
│  │Sector 0 │Sector 1 │Sector 2 │  ...    │          │
│  │(暗号文) │(暗号文) │(暗号文) │         │          │
│  └─────────┴─────────┴─────────┴─────────┘          │
└──────────────────────────────────────────────────────┘
```

### 5.3 dm-crypt の暗号化フロー

dm-crypt は Linux の Device Mapper フレームワーク上に構築された暗号化レイヤーである。

```
暗号化の全体フロー（書き込み時）:

アプリケーション
    │ write("Hello World")
    ▼
glibc: write() システムコール
    │
    ▼
VFS (Virtual File System)
    │ ファイル → inode → ブロック番号に変換
    ▼
ext4 ファイルシステム
    │ ブロック書き込み要求を生成
    │ (例: ブロック 1234 に "Hello World" を書き込み)
    ▼
Virtual Block Device (/dev/mapper/sda5_crypt)
    │
    ▼
dm-crypt カーネルモジュール
    │
    │ 暗号化処理:
    │ ┌──────────────────────────────────────────┐
    │ │ 1. セクター番号から tweak 値を計算        │
    │ │    tweak = sector_number                  │
    │ │                                           │
    │ │ 2. AES-256-XTS で暗号化                   │
    │ │    - Key1 (256-bit): データ暗号化用       │
    │ │    - Key2 (256-bit): tweak 暗号化用       │
    │ │                                           │
    │ │    XTS モードの動作:                       │
    │ │    T = AES_K2(sector_number)               │
    │ │    C = AES_K1(P XOR T) XOR T              │
    │ │    (P=平文, C=暗号文, T=tweak値)          │
    │ │                                           │
    │ │ 3. 同じ平文でも、セクター位置が異なれば   │
    │ │    異なる暗号文になる（tweak の効果）      │
    │ └──────────────────────────────────────────┘
    │
    ▼
物理ブロックデバイス (/dev/sda5)
    │ 暗号化されたデータをディスクに書き込み
    ▼
物理ディスク (暗号文が格納される)


復号の全体フロー（読み込み時）は逆順:
  物理ディスク → dm-crypt (復号) → ext4 → VFS → アプリケーション
```

#### パフォーマンスへの影響

```bash
# 暗号化のパフォーマンス測定
cryptsetup benchmark
# 出力例:
# # Tests are approximate using memory only (no storage IO).
# PBKDF2-sha1       1234567 iterations per second for 256-bit key
# PBKDF2-sha256      987654 iterations per second for 256-bit key
#     Algorithm |       Key |      Encryption |      Decryption
#         aes-cbc        128b       1234.5 MiB/s       5678.9 MiB/s
#         aes-cbc        256b       1000.0 MiB/s       4567.8 MiB/s
#         aes-xts        256b       4567.8 MiB/s       4567.8 MiB/s
#         aes-xts        512b       3456.7 MiB/s       3456.7 MiB/s

# AES-NI（ハードウェアAESアクセラレーション）の確認
grep aes /proc/cpuinfo
# flags に "aes" が含まれていれば AES-NI 対応

# LUKS の状態確認
sudo cryptsetup status sda5_crypt
# 出力例:
# /dev/mapper/sda5_crypt is active and is in use.
#   type:    LUKS2
#   cipher:  aes-xts-plain64
#   keysize: 512 bits
#   key location: dm-crypt
#   device:  /dev/sda5
#   sector size:  512
#   offset:  32768 sectors
#   size:    38797312 sectors
#   mode:    read/write
```

### 5.4 AES-256-XTS の概要

- **AES (Advanced Encryption Standard)**: NIST が2001年に標準化した対称暗号アルゴリズム。元は Rijndael 暗号
- **256**: 鍵長 256 ビット。総当たり攻撃に必要な計算量は 2^256（宇宙の原子数 ≈ 2^266 と比較されるほど膨大）
- **XTS (XEX-based Tweaked-codebook mode with ciphertext Stealing)**: ディスク暗号化に特化したブロック暗号モード。各セクターの位置情報（tweak）を暗号化に組み込むことで、同じ平文でも異なる位置では異なる暗号文になる

### 5.5 なぜ暗号化が必要か - 具体的脅威シナリオ

**シナリオ1: 物理的盗難**
データセンターからサーバーが盗まれる、またはラップトップが盗まれる。暗号化なしの場合、ディスクを別のマシンに接続するだけで全データにアクセス可能。暗号化ありの場合、パスフレーズなしにはデータを読み取れない。

**シナリオ2: 廃棄時のデータ漏洩**
サーバーのディスクを廃棄する際、通常のフォーマットではデータ復旧ソフトで読み取りが可能。暗号化されたディスクの場合、暗号鍵を破棄すれば（ヘッダーを上書きすれば）データは永久に読み取り不可能。

**シナリオ3: コンプライアンス要件**
GDPR（EU一般データ保護規則）、HIPAA（米国医療保険の携行性と責任に関する法律）、PCI DSS（クレジットカード業界セキュリティ基準）など、多くの規制が保存データの暗号化を要求している。

LUKS の主要コマンド:
```bash
# 暗号化パーティションの作成
sudo cryptsetup luksFormat /dev/sda2

# 暗号化パーティションを開く
sudo cryptsetup open /dev/sda2 sda2_crypt

# 状態確認
sudo cryptsetup status sda2_crypt

# ヘッダー情報の表示
sudo cryptsetup luksDump /dev/sda2
# 出力例:
# LUKS header information
# Version:        2
# Epoch:          3
# Metadata area:  16384 [bytes]
# Keyslots area:  16744448 [bytes]
# UUID:           xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
# Label:          (no label)
# ...
# Keyslots:
#   0: luks2
#     Key:        512 bits
#     Priority:   normal
#     Cipher:     aes-xts-plain64
#     Cipher key: 512 bits
#     PBKDF:      argon2id
#     ...

# キースロットの追加（バックアップパスフレーズ）
sudo cryptsetup luksAddKey /dev/sda2

# キースロットの削除
sudo cryptsetup luksRemoveKey /dev/sda2

# 暗号化パーティションを閉じる
sudo cryptsetup close sda2_crypt

# ヘッダーのバックアップ
sudo cryptsetup luksHeaderBackup /dev/sda2 --header-backup-file /root/luks_header.bak
```

---

## 6. パーティションテーブルとブートプロセス

### 6.1 MBR (Master Boot Record)

1983年に導入された従来のパーティションテーブル形式。

```
MBR の構造（512 bytes）:

Offset  Size     内容
────────────────────────────────────
0x000   446 B    ブートストラップコード
                 (Stage 1 ブートローダー)
0x1BE   16 B     パーティションエントリ #1
0x1CE   16 B     パーティションエントリ #2
0x1DE   16 B     パーティションエントリ #3
0x1EE   16 B     パーティションエントリ #4
0x1FE   2 B      マジックナンバー (0x55AA)

パーティションエントリの構造（16 bytes）:
┌────┬────────┬────┬────────┬──────┬──────┐
│Flag│CHS開始 │Type│CHS終了 │LBA   │セクタ│
│(1B)│(3B)    │(1B)│(3B)    │開始  │数    │
│    │        │    │        │(4B)  │(4B)  │
└────┴────────┴────┴────────┴──────┴──────┘
Flag: 0x80=アクティブ(ブート可能), 0x00=非アクティブ
Type: 0x83=Linux, 0x82=Linux swap, 0x8e=Linux LVM
```

特徴:
- プライマリパーティション最大 **4つ**（拡張パーティションを使えばそれ以上）
- 最大ディスクサイズ **2TB**（32bit LBA x 512 byte/sector = 2^32 x 512 = 2TB）
- 冗長性がない（MBR が壊れるとパーティション情報が失われる）

### 6.2 GPT (GUID Partition Table)

UEFI 仕様の一部として策定された新しいパーティションテーブル形式。

特徴:
- パーティション最大 **128個**（デフォルト）
- 最大ディスクサイズ **9.4ZB (ゼタバイト)**（64bit LBA）
- CRC32 チェックサムによるデータ整合性の検証
- バックアップパーティションテーブルをディスク末尾に保持（冗長性）
- UEFI ブートに対応
- Protective MBR をディスク先頭に配置（MBR ツールによる誤操作を防止）

### 6.3 ブートプロセスの完全解説

Born2beRoot の構成では、電源投入から SSH ログイン可能になるまで、以下のプロセスが順に実行される:

```
電源ON
  │
  ▼
BIOS/UEFI (ファームウェア)
  │ POST (Power-On Self-Test): ハードウェアの検査
  │  - CPU の自己テスト
  │  - メモリ (RAM) のテスト
  │  - ストレージデバイスの検出
  │  - ビデオカードの初期化
  │ ブートデバイスの検索 (起動順序に従って)
  │ MBR の先頭 512 bytes を読み込み
  ▼
Stage 1 Bootloader (MBR内、446 bytes)
  │ GRUB の core.img の位置を知っている
  │ MBR と最初のパーティションの間の領域 (MBR gap) を使用
  ▼
Stage 1.5 Bootloader (MBR gap内)
  │ ファイルシステムドライバを含む
  │ /boot パーティションを読み取る能力を持つ
  ▼
Stage 2 Bootloader (GRUB2, /boot/grub/)
  │ grub.cfg を読み込み
  │ ブートメニューを表示
  │ ユーザーがカーネルを選択（またはタイムアウトでデフォルト選択）
  │ Linux カーネル (vmlinuz) を メモリにロード
  │ initrd/initramfs をメモリにロード
  │ カーネルにパラメータを渡して制御を移す
  ▼
Linux Kernel の初期起動
  │ カーネルの自己解凍（vmlinuz → vmlinux）
  │ CPU の初期化（モード設定、割り込みテーブル設定）
  │ メモリ管理の初期化（ページテーブル設定）
  │ コンソールの初期化（dmesg 出力開始）
  │ ドライバの初期化（ストレージ、ネットワーク等）
  │ initramfs をルートファイルシステムとしてマウント
  ▼
initramfs (Initial RAM Filesystem)
  │ 最小限の Linux 環境（busybox, cryptsetup 等を含む）
  │
  │ ★ LUKS パスフレーズの入力を要求 ★
  │   → cryptsetup open /dev/sda5 sda5_crypt
  │   → パスフレーズを PBKDF2/Argon2 で処理
  │   → マスター鍵を復号
  │
  │ dm-crypt が暗号化パーティションを復号
  │ LVM を起動 (vgscan, vgchange -ay)
  │ 各 LV を認識 (/dev/LVMGroup/root 等)
  │ 本来のルートファイルシステム (LVMGroup-root) をマウント
  │ pivot_root / switch_root でルートを切り替え
  │ initramfs のリソースを解放
  ▼
systemd (PID 1)
  │ default.target の依存関係ツリーを解析
  │ 各 unit を並列に起動:
  │   ├── local-fs.target
  │   │   └── /etc/fstab の全マウントポイントをマウント
  │   │       (/home, /var, /srv, /tmp, /var/log)
  │   ├── network.target
  │   │   └── networking.service: ネットワークの設定
  │   │       (DHCP で IP アドレス取得: 10.0.2.15)
  │   ├── apparmor.service
  │   │   └── AppArmor プロファイルのロード
  │   ├── ufw.service
  │   │   └── ファイアウォールルールの適用
  │   │       (port 4242 のみ許可)
  │   ├── ssh.service
  │   │   └── SSH デーモンの起動 (port 4242 で LISTEN)
  │   ├── cron.service
  │   │   └── cron デーモンの起動
  │   │       (*/10 で monitoring.sh を実行)
  │   └── getty@tty1.service
  │       └── ログインプロンプトの表示
  ▼
ログインプロンプト / SSH 接続受付
  [ユーザーがローカルまたは SSH でログイン可能]
```

### 6.4 GRUB (GRand Unified Bootloader)

**GRUB2** は、Linux で最も広く使用されるブートローダーである。

設定ファイル:
- `/boot/grub/grub.cfg`: GRUB の設定ファイル（自動生成、直接編集しない）
- `/etc/default/grub`: GRUB の設定パラメータ
- `/etc/grub.d/`: 設定スクリプト群
- 更新コマンド: `update-grub`

```bash
# /etc/default/grub の主要設定
cat /etc/default/grub
# GRUB_DEFAULT=0               # デフォルトのメニューエントリ
# GRUB_TIMEOUT=5               # タイムアウト（秒）
# GRUB_DISTRIBUTOR="Debian"    # ディストリビューション名
# GRUB_CMDLINE_LINUX_DEFAULT="quiet"  # カーネルパラメータ
# GRUB_CMDLINE_LINUX=""        # 追加のカーネルパラメータ

# GRUB 設定の更新（変更後に必ず実行）
sudo update-grub
```

---

## 7. Linux ファイルシステム階層と ext4 の内部構造

### 7.1 Filesystem Hierarchy Standard (FHS)

Linux のディレクトリ構造は **FHS (Filesystem Hierarchy Standard)** に基づいて標準化されている。

```
/
├── boot/     ブートローダー、カーネルイメージ (vmlinuz, initrd)
│   ├── vmlinuz-5.10.0-XX-amd64       カーネル本体（圧縮済み）
│   ├── initrd.img-5.10.0-XX-amd64    初期RAMディスク
│   ├── config-5.10.0-XX-amd64        カーネルビルド設定
│   ├── System.map-5.10.0-XX-amd64    シンボルテーブル
│   └── grub/                          GRUB2 の設定とモジュール
│       ├── grub.cfg                   ブートメニュー設定
│       └── fonts/                     ブート画面フォント
├── bin/ → usr/bin  基本コマンドのバイナリ
├── sbin/ → usr/sbin  システム管理用バイナリ
├── etc/      システム設定ファイル (全てテキストファイル)
│   ├── ssh/           SSH 設定
│   │   ├── sshd_config       サーバー設定
│   │   ├── ssh_config        クライアント設定
│   │   ├── ssh_host_*_key    ホスト秘密鍵
│   │   └── ssh_host_*_key.pub  ホスト公開鍵
│   ├── pam.d/         PAM 設定
│   │   ├── common-password   パスワードポリシー
│   │   ├── common-auth       認証設定
│   │   ├── common-account    アカウント管理
│   │   └── common-session    セッション管理
│   ├── sudoers.d/     sudo 追加設定
│   │   └── sudo_config       Born2beRoot の sudo 設定
│   ├── apparmor.d/    AppArmor プロファイル
│   ├── ufw/           UFW 設定
│   ├── fstab          マウントポイント設定
│   ├── crypttab       暗号化ボリューム設定
│   ├── hostname       ホスト名
│   ├── hosts          ローカル名前解決
│   ├── resolv.conf    DNS 設定
│   ├── passwd         ユーザー情報
│   ├── shadow         パスワードハッシュ
│   ├── group          グループ情報
│   ├── gshadow        グループパスワード
│   ├── login.defs     ログイン設定（パスワード期限等）
│   ├── os-release     OS 情報
│   └── default/       サービスのデフォルト設定
│       ├── grub       GRUB 設定
│       └── ssh        SSH デフォルト設定
├── home/     ユーザーのホームディレクトリ
│   └── kaztakam/
│       ├── .bashrc        シェルの設定
│       ├── .profile       ログイン時の設定
│       └── .ssh/          SSH ユーザー設定
│           ├── authorized_keys  許可された公開鍵
│           └── known_hosts      接続したホストの鍵
├── root/     root ユーザーのホームディレクトリ
├── var/      可変データ
│   ├── log/   ログファイル
│   │   ├── syslog        システムログ
│   │   ├── auth.log      認証ログ（SSH ログイン試行等）
│   │   ├── kern.log      カーネルログ
│   │   ├── dpkg.log      パッケージ管理ログ
│   │   └── sudo/         sudo ログ
│   │       └── sudo.log  sudo コマンドのログ
│   ├── cache/ キャッシュ
│   │   └── apt/          APT パッケージキャッシュ
│   ├── lib/   アプリケーションデータ
│   │   └── dpkg/         dpkg データベース
│   └── spool/ スプール
│       └── cron/         cron ジョブキュー
├── tmp/      一時ファイル (再起動時に削除される)
├── usr/      ユーザー用プログラム (読み取り専用)
│   ├── bin/       ユーザーコマンド
│   ├── sbin/      システム管理コマンド
│   ├── lib/       共有ライブラリ
│   ├── local/     ローカルインストール
│   │   └── bin/   monitoring.sh の配置場所
│   └── share/     アーキテクチャ非依存データ
│       └── man/   マニュアルページ
├── srv/      サービスが提供するデータ (Web, FTP)
├── dev/      デバイスファイル
│   ├── sda, sda1, sda2  ディスクデバイス
│   ├── mapper/           Device Mapper デバイス
│   │   └── sda5_crypt    LUKS 暗号化デバイス
│   ├── null              出力破棄 (/dev/null)
│   ├── zero              ゼロバイト生成
│   ├── random            暗号学的乱数
│   ├── urandom           非ブロッキング乱数
│   └── pts/              仮想端末
├── proc/     プロセス情報（仮想ファイルシステム - procfs）
│   ├── cpuinfo          CPU 情報
│   ├── meminfo          メモリ情報
│   ├── uptime           稼働時間
│   ├── loadavg          ロードアベレージ
│   ├── partitions       パーティション一覧
│   ├── net/             ネットワーク統計
│   │   └── tcp          TCP 接続情報
│   ├── [PID]/           プロセスごとの情報
│   │   ├── status       プロセス状態
│   │   ├── cmdline      コマンドライン
│   │   ├── maps         メモリマッピング
│   │   └── fd/          ファイルディスクリプタ
│   └── sys/             カーネルパラメータ（sysctl）
│       ├── net/         ネットワーク設定
│       ├── kernel/      カーネル設定
│       └── vm/          仮想メモリ設定
├── sys/      カーネル/デバイス情報（仮想FS - sysfs）
├── lib/ → usr/lib  共有ライブラリ
├── media/    リムーバブルメディアのマウントポイント
├── mnt/      一時的なマウントポイント
├── opt/      追加アプリケーション
└── run/      ランタイムデータ (PID ファイル、ソケット)
    ├── sshd.pid          sshd のプロセスID
    └── ufw/              UFW ランタイムデータ
```

### 7.2 /proc と /sys ファイルシステム

#### /proc (procfs)

/proc は仮想ファイルシステムで、カーネルがランタイムに動的に生成する情報を提供する。ディスク上にファイルは存在しない。

Born2beRoot で重要な /proc エントリ:

| パス | 内容 | monitoring.sh での使用 |
|------|------|----------------------|
| `/proc/cpuinfo` | CPU 情報 | 物理/仮想 CPU 数の取得 |
| `/proc/meminfo` | メモリ情報 | free コマンドが内部で参照 |
| `/proc/uptime` | 稼働時間 | システムの稼働秒数 |
| `/proc/loadavg` | ロードアベレージ | CPU 負荷の指標 |
| `/proc/partitions` | パーティション一覧 | ブロックデバイスの確認 |
| `/proc/net/tcp` | TCP 接続情報 | ss コマンドが内部で参照 |
| `/proc/[PID]/` | プロセス情報 | 各プロセスの詳細 |

```bash
# /proc/cpuinfo の読み方（monitoring.sh で使用）
cat /proc/cpuinfo
# processor       : 0           ← 論理プロセッサ番号（0始まり）
# vendor_id       : GenuineIntel
# cpu family      : 6
# model           : 142
# model name      : Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz
# stepping        : 10
# microcode       : 0xffffffff
# cpu MHz         : 1992.000
# cache size      : 8192 KB
# physical id     : 0           ← 物理 CPU の ID
# siblings        : 2           ← この物理 CPU の論理プロセッサ数
# core id         : 0           ← コア ID
# cpu cores       : 2           ← この物理 CPU のコア数
# flags           : fpu vme de pse tsc msr pae mce cx8 apic sep
#                   mtrr pge mca cmov pat pse36 clflush mmx fxsr
#                   sse sse2 ht syscall nx rdtscp lm constant_tsc
#                   rep_good nopl xtopology ...

# 物理CPU数の取得
grep "physical id" /proc/cpuinfo | sort -u | wc -l
# 出力: 1

# 仮想CPU数の取得
grep "^processor" /proc/cpuinfo | wc -l
# 出力: 1 (または 2 等)

# /proc/meminfo の主要項目
cat /proc/meminfo | head -10
# MemTotal:         470000 kB   ← 合計メモリ
# MemFree:          150000 kB   ← 未使用メモリ
# MemAvailable:     300000 kB   ← 利用可能メモリ
# Buffers:           20000 kB   ← I/O バッファ
# Cached:           120000 kB   ← ページキャッシュ
# SwapCached:            0 kB   ← スワップキャッシュ
# Active:           200000 kB   ← アクティブなページ
# Inactive:         100000 kB   ← 非アクティブなページ
# SwapTotal:        976000 kB   ← スワップ合計
# SwapFree:         976000 kB   ← スワップ空き
```

### 7.3 ext4 ファイルシステムの内部構造

Born2beRoot で使用される ext4 ファイルシステムの内部構造を詳しく解説する。

#### inode (index node)

inode はファイルのメタデータを格納するデータ構造。ファイル名以外の全ての情報を持つ。

```
inode の構造（256 bytes、ext4 の場合）:
┌──────────────────────────────────────────┐
│ i_mode          (2B)  ファイルタイプ +    │
│                       パーミッション      │
│ i_uid           (2B)  所有者 UID         │
│ i_size_lo       (4B)  ファイルサイズ(下位)│
│ i_atime         (4B)  最終アクセス時刻    │
│ i_ctime         (4B)  inode変更時刻      │
│ i_mtime         (4B)  データ変更時刻      │
│ i_dtime         (4B)  削除時刻           │
│ i_gid           (2B)  グループ GID       │
│ i_links_count   (2B)  ハードリンク数      │
│ i_blocks_lo     (4B)  使用ブロック数      │
│ i_flags         (4B)  フラグ             │
│ i_block[15]     (60B) データブロック      │
│                       ポインタ           │
│ ...                                      │
└──────────────────────────────────────────┘

データブロックポインタ (i_block[15]):
┌────────────────────────────────────────────┐
│ [0]-[11]: 直接ポインタ (12個)              │
│   → 12 x 4KB = 48KB まで直接参照           │
│                                             │
│ [12]: 間接ポインタ                          │
│   → 4KB/4B = 1024 ポインタ                  │
│   → 1024 x 4KB = 4MB                       │
│                                             │
│ [13]: 二重間接ポインタ                      │
│   → 1024 x 1024 x 4KB = 4GB                │
│                                             │
│ [14]: 三重間接ポインタ                      │
│   → 1024 x 1024 x 1024 x 4KB = 4TB         │
│                                             │
│ ※ ext4 では extent ベースの管理も使用       │
│   (連続したブロックを効率的に管理)          │
└────────────────────────────────────────────┘

ファイル名はどこにある？
  → inode にはファイル名がない
  → ディレクトリエントリ（dentry）に格納される

ディレクトリの構造:
┌──────────────┬─────────┬──────────┐
│ inode number │ rec_len │ name_len │ name
├──────────────┼─────────┼──────────┤
│     2        │   12    │    1     │ "."       (自分)
│     2        │   12    │    2     │ ".."      (親)
│   100        │   16    │    5     │ "hello"   (ファイル)
│   101        │   20    │    8     │ "world.txt"
└──────────────┴─────────┴──────────┘
```

```bash
# inode 情報の確認
stat /etc/hostname
# 出力例:
#   File: /etc/hostname
#   Size: 11        	Blocks: 8          IO Block: 4096   regular file
#   Device: fd00h/64768d	Inode: 131074      Links: 1
#   Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
#   Access: 2024-01-15 10:00:00.000000000 +0000
#   Modify: 2024-01-15 09:30:00.000000000 +0000
#   Change: 2024-01-15 09:30:00.000000000 +0000
#    Birth: 2024-01-15 09:30:00.000000000 +0000

# inode 使用状況
df -i
# 出力例:
# Filesystem       Inodes  IUsed  IFree IUse% Mounted on
# /dev/mapper/LVMGroup-root
#                   655360  50000 605360    8% /

# ファイルの inode 番号を表示
ls -i /etc/hostname
# 131074 /etc/hostname

# 特定の inode 番号のファイルを検索
find / -inum 131074
```

#### ext4 のディスクレイアウト

```
ext4 ファイルシステムの全体構造:

┌──────────────────────────────────────────────────────────┐
│ Boot Block │ Block Group 0 │ Block Group 1 │ BG 2 │ ... │
│ (1024 B)   │               │               │      │     │
└────────────┼───────────────┼───────────────┼──────┼─────┘
             │
             ▼
Block Group 0 の詳細:
┌─────────┬──────────┬──────────┬──────────┬──────────┬──────────┐
│ Super   │ Group    │ Block    │ inode    │ inode    │ Data     │
│ Block   │ Desc.    │ Bitmap   │ Bitmap   │ Table    │ Blocks   │
│ (1 blk) │ Table    │ (1 blk)  │ (1 blk)  │ (N blk)  │          │
│         │ (N blk)  │          │          │          │          │
└─────────┴──────────┴──────────┴──────────┴──────────┴──────────┘

Superblock の主要フィールド:
┌──────────────────────────────────────────┐
│ s_inodes_count        inode の総数       │
│ s_blocks_count        ブロックの総数     │
│ s_free_blocks_count   空きブロック数     │
│ s_free_inodes_count   空き inode 数     │
│ s_log_block_size      ブロックサイズ     │
│                       (0=1KB,1=2KB,2=4KB)│
│ s_blocks_per_group    グループあたりの   │
│                       ブロック数         │
│ s_inodes_per_group    グループあたりの   │
│                       inode 数          │
│ s_magic               マジックナンバー   │
│                       (0xEF53)           │
│ s_feature_compat      互換機能フラグ     │
│ s_feature_incompat    非互換機能フラグ   │
│ s_feature_ro_compat   読取専用互換機能   │
│ s_uuid                UUID              │
│ s_volume_name         ボリューム名       │
└──────────────────────────────────────────┘
```

#### ext4 のジャーナリング (Journaling)

ext4 はジャーナリングファイルシステムであり、電源断やクラッシュ時のデータ整合性を保護する。

```
ジャーナリングの動作原理:

通常の書き込み（ジャーナルなし）の場合:
  1. メタデータを更新（inode, bitmap等）
  2. データブロックに書き込み
  → 1と2の間でクラッシュすると不整合が発生

ジャーナリングありの場合:
  1. トランザクション開始をジャーナルに記録
  2. 変更内容をジャーナルに書き込み（ジャーナルコミット）
  3. 実際のファイルシステムを更新
  4. ジャーナルのトランザクションを完了としてマーク
  → 2と3の間でクラッシュしても、ジャーナルから復旧可能

┌──────────────────────────────────────────────┐
│  ジャーナルの書き込みフロー:                   │
│                                               │
│  Step 1: ジャーナルに記録                     │
│  ┌─────────┬──────────┬──────────┬─────────┐ │
│  │ Desc.   │ メタ     │ データ   │ Commit  │ │
│  │ Block   │ データ   │ ブロック │ Block   │ │
│  └─────────┴──────────┴──────────┴─────────┘ │
│       ↓                                       │
│  Step 2: 実ファイルシステムに反映             │
│  ┌──────────────────────────────────────┐    │
│  │  ext4 のメタデータ + データブロック   │    │
│  └──────────────────────────────────────┘    │
│       ↓                                       │
│  Step 3: ジャーナルのトランザクションを解放   │
└──────────────────────────────────────────────┘
```

ジャーナリングモード:

| モード | メタデータ | データ | 性能 | 安全性 |
|--------|----------|--------|------|--------|
| journal | ジャーナル | ジャーナル | 低 | 最高 |
| ordered (デフォルト) | ジャーナル | 直接書き込み | 中 | 高 |
| writeback | ジャーナル | 直接書き込み | 高 | 低 |

```bash
# ファイルシステムの情報確認
sudo tune2fs -l /dev/LVMGroup/root
# 出力例:
# Filesystem volume name:   <none>
# Filesystem UUID:          xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
# Filesystem features:      has_journal ext_attr resize_inode dir_index
#                           filetype needs_recovery extent flex_bg
#                           sparse_super large_file huge_file dir_nlink
#                           extra_isize metadata_csum
# Filesystem state:         clean
# Inode count:              655360
# Block count:              2621440
# Free blocks:              1500000
# Free inodes:              600000
# Block size:               4096
# Journal size:             64M

# ファイルシステムの整合性チェック（アンマウント状態で実行）
sudo e2fsck -f /dev/LVMGroup/root

# マウントオプションの確認
mount | grep "on / "
# 出力例: /dev/mapper/LVMGroup-root on / type ext4 (rw,relatime,errors=remount-ro)
```

---

## 8. ファイアウォール (Firewall)

### 8.1 ファイアウォールとは何か

ファイアウォールは、ネットワークトラフィックを監視し、事前に定義されたルールに基づいてパケットの通過を許可または拒否するセキュリティシステムである。

Linux におけるファイアウォールの構造:
```
┌──────────────────────────────────────┐
│          User Space Tools            │
│  ┌──────┐  ┌──────────┐  ┌────────┐ │
│  │ UFW  │  │ firewalld│  │iptables│ │
│  │      │  │          │  │/nft    │ │
│  └──┬───┘  └────┬─────┘  └───┬────┘ │
│     │           │             │      │
│  ┌──┴───────────┴─────────────┴────┐ │
│  │     iptables / nftables API     │ │
│  │                                 │ │
│  │  iptables: 従来のインターフェース│ │
│  │  nftables: 新しいインターフェース│ │
│  │  (Debian 10+ で nftables が推奨)│ │
│  └──────────────┬──────────────────┘ │
├─────────────────┼────────────────────┤
│  ┌──────────────┴──────────────────┐ │
│  │      Netfilter Framework        │ │
│  │  (Linux カーネル内蔵)            │ │
│  │                                 │ │
│  │  ┌─────────────────────────┐    │ │
│  │  │ Hook Points:            │    │ │
│  │  │  NF_INET_PRE_ROUTING    │    │ │
│  │  │  NF_INET_LOCAL_IN       │    │ │
│  │  │  NF_INET_FORWARD        │    │ │
│  │  │  NF_INET_LOCAL_OUT      │    │ │
│  │  │  NF_INET_POST_ROUTING   │    │ │
│  │  └─────────────────────────┘    │ │
│  │                                 │ │
│  │  ┌─────────────────────────┐    │ │
│  │  │ Connection Tracking     │    │ │
│  │  │ (conntrack)             │    │ │
│  │  │ 接続の状態を追跡:       │    │ │
│  │  │  NEW, ESTABLISHED,      │    │ │
│  │  │  RELATED, INVALID       │    │ │
│  │  └─────────────────────────┘    │ │
│  └─────────────────────────────────┘ │
│              Kernel Space            │
└──────────────────────────────────────┘
```

### 8.2 Netfilter のフックポイントとパケットの流れ

```
                    ┌─────────────┐
     受信パケット → │ PREROUTING  │
                    │ (DNAT,      │
                    │  raw,       │
                    │  conntrack) │
                    └──────┬──────┘
                           │
                    ┌──────┴──────┐
                    │ ルーティング │
                    │   判断      │
                    └──┬──────┬───┘
                       │      │
              自分宛   │      │ 転送（この VM では通常使わない）
                       ▼      ▼
                 ┌─────────┐ ┌─────────┐
                 │  INPUT  │ │ FORWARD │
                 │(filter) │ │(filter) │
                 └────┬────┘ └────┬────┘
                      │           │
                      ▼           │
               ローカルプロセス    │
               (sshd, cron,      │
                ufw, etc.)       │
                      │           │
                      ▼           │
                 ┌─────────┐      │
                 │  OUTPUT │      │
                 │(filter, │      │
                 │ nat)    │      │
                 └────┬────┘      │
                      │           │
                      └─────┬─────┘
                            ▼
                    ┌───────────────┐
                    │ POSTROUTING   │
                    │ (SNAT,        │
                    │  MASQUERADE)  │
                    └───────┬───────┘
                            │
                     送信パケット →
```

### 8.3 iptables の詳細 - テーブルとチェーン

| テーブル | 用途 | 使用するチェーン |
|---------|------|----------------|
| **filter** | パケットフィルタリング（デフォルト） | INPUT, FORWARD, OUTPUT |
| **nat** | アドレス変換 (SNAT, DNAT, MASQUERADE) | PREROUTING, OUTPUT, POSTROUTING |
| **mangle** | パケットヘッダの書き換え (TTL, TOS) | 全チェーン |
| **raw** | 接続追跡 (conntrack) の例外設定 | PREROUTING, OUTPUT |

Born2beRoot では主に **filter** テーブルの **INPUT** チェーンを使用する。

```bash
# iptables のルール一覧（実際に UFW が設定したルール）
sudo iptables -L -n -v
# 出力例:
# Chain INPUT (policy DROP 0 packets, 0 bytes)
#  pkts bytes target     prot opt in     out     source      destination
#  1000 80000 ufw-before-input  all  --  *      *       0.0.0.0/0    0.0.0.0/0
#
# Chain ufw-user-input (1 references)
#  pkts bytes target     prot opt in     out     source      destination
#   500 40000 ACCEPT     tcp  --  *      *       0.0.0.0/0    0.0.0.0/0  tcp dpt:4242
#   100  8000 ACCEPT     udp  --  *      *       0.0.0.0/0    0.0.0.0/0  udp dpt:4242

# NAT テーブルの表示
sudo iptables -t nat -L -n -v

# 接続追跡テーブルの表示
sudo conntrack -L
# または
cat /proc/net/nf_conntrack
```

### 8.4 UFW (Uncomplicated Firewall)

**UFW** は iptables のフロントエンドで、シンプルなインターフェースでファイアウォールを管理できる。Debian で使用する。

```bash
# UFW のインストール
sudo apt install ufw

# UFW の有効化
sudo ufw enable
# 出力: Firewall is active and enabled on system startup

# UFW の状態確認
sudo ufw status verbose
# 出力例:
# Status: active
# Logging: on (low)
# Default: deny (incoming), allow (outgoing), disabled (routed)
# New profiles: skip
#
# To                         Action      From
# --                         ------      ----
# 4242                       ALLOW IN    Anywhere
# 4242 (v6)                  ALLOW IN    Anywhere (v6)

# ポートの許可
sudo ufw allow 4242

# 特定プロトコルのみ許可
sudo ufw allow 4242/tcp

# 特定の IP からのアクセスのみ許可
sudo ufw allow from 192.168.1.0/24 to any port 4242

# ポートの拒否
sudo ufw deny 80

# ルールの削除
sudo ufw delete allow 80

# ルール番号で管理
sudo ufw status numbered
# 出力例:
#      To                         Action      From
#      --                         ------      ----
# [ 1] 4242                       ALLOW IN    Anywhere
# [ 2] 4242 (v6)                  ALLOW IN    Anywhere (v6)

sudo ufw delete 2    # ルール番号 2 を削除

# デフォルトポリシー
sudo ufw default deny incoming     # 受信は拒否
sudo ufw default allow outgoing    # 送信は許可

# UFW のリセット（全ルール削除）
sudo ufw reset

# ログの有効化
sudo ufw logging on
# ログは /var/log/ufw.log に記録される
```

#### UFW の設定ファイル

```bash
# UFW の設定ファイルの場所
ls /etc/ufw/
# before.rules     ← UFW ルールの前に適用される iptables ルール
# after.rules      ← UFW ルールの後に適用される iptables ルール
# before6.rules    ← IPv6 版
# after6.rules     ← IPv6 版
# ufw.conf         ← UFW のメイン設定
# user.rules       ← ユーザーが定義したルール
# user6.rules      ← IPv6 版

# UFW の自動起動設定
cat /etc/ufw/ufw.conf
# ENABLED=yes    ← 起動時に自動有効化
```

### 8.5 firewalld (Rocky Linux の場合)

**firewalld** は Rocky Linux のデフォルトファイアウォールで、zone ベースの管理を提供する。

```bash
# 状態確認
sudo firewall-cmd --state

# ポートの追加
sudo firewall-cmd --permanent --add-port=4242/tcp

# 設定の再読み込み
sudo firewall-cmd --reload

# ルールの一覧
sudo firewall-cmd --list-all
# 出力例:
# public (active)
#   target: default
#   interfaces: enp0s3
#   ports: 4242/tcp
#   ...
```

---

## 9. SSH (Secure Shell)

### 9.1 SSH とは何か

**SSH (Secure Shell)** は、ネットワーク上で安全にリモートアクセスするためのプロトコル（RFC 4253）およびソフトウェアスイートである。通信はすべて暗号化される。

SSH の主な用途:
- リモートログイン（telnet の安全な代替）
- リモートコマンド実行
- ファイル転送（SCP, SFTP）
- ポートフォワーディング（トンネリング）
- X11 フォワーディング

### 9.2 SSH の暗号化の仕組み

SSH の接続確立プロセス:

```
Client                                Server (port 4242)
  │                                    │
  │── TCP 3-way handshake ────────────→│  (1) TCP接続の確立
  │←────────────────────── SYN-ACK ───│
  │── ACK ────────────────────────────→│
  │                                    │
  │←── Protocol Version Exchange ────→│  (2) SSHバージョンの交換
  │  "SSH-2.0-OpenSSH_9.2p1"          │      "SSH-2.0-OpenSSH_9.2p1"
  │                                    │
  │←── Key Exchange Init ────────────→│  (3) アルゴリズムネゴシエーション
  │  対称暗号: aes256-gcm             │      鍵交換: curve25519-sha256
  │  MAC: hmac-sha2-256               │      ホスト鍵: ssh-ed25519
  │                                    │
  │←── Diffie-Hellman Key Exchange ──→│  (4) 鍵交換（共有秘密の確立）
  │  Client DH public value ──────────→│
  │←── Server DH public value ────────│
  │  両者が独立に共有秘密を計算        │
  │  (第三者は傍受しても計算不可能)     │
  │                                    │
  │←── Server Host Key ──────────────│  (5) サーバー認証
  │  サーバーのホスト鍵で署名          │      known_hosts と照合
  │  (初回接続時はフィンガープリント    │
  │   の確認を求められる)              │
  │                                    │
  │──── User Authentication ─────────→│  (6) ユーザー認証
  │  パスワード認証 or 公開鍵認証      │
  │                                    │
  │←── Encrypted Session ────────────→│  (7) 暗号化セッション確立
```

#### Diffie-Hellman 鍵交換の概念

```
Diffie-Hellman 鍵交換の仕組み（簡略化）:

前提: 素数 p と生成元 g が公開されている

Client                          Server
  │                              │
  │ 秘密値 a を生成              │ 秘密値 b を生成
  │ A = g^a mod p を計算         │ B = g^b mod p を計算
  │                              │
  │──── A を送信 ──────────────→│
  │←──── B を送信 ──────────────│
  │                              │
  │ 共有秘密:                    │ 共有秘密:
  │ K = B^a mod p                │ K = A^b mod p
  │   = (g^b)^a mod p            │   = (g^a)^b mod p
  │   = g^(ab) mod p             │   = g^(ab) mod p
  │                              │
  │ 両者が同じ K を計算!          │
  │                              │
  盗聴者は A と B を知っているが:
  A = g^a mod p から a を求めるのは
  「離散対数問題」として計算量的に困難
  → 共有秘密 K を計算できない

現在推奨: curve25519-sha256（楕円曲線DH）
  - 従来の DH より短い鍵長で同等の安全性
  - 計算が高速
  - 鍵長 256 bit で RSA 3072 bit 相当の安全性
```

### 9.3 公開鍵認証

**公開鍵暗号方式** を利用した認証は、パスワード認証より安全である。

```bash
# 鍵ペアの生成（Ed25519 推奨）
ssh-keygen -t ed25519 -C "your_email@example.com"
# 出力:
# Generating public/private ed25519 key pair.
# Enter file in which to save the key (/home/user/.ssh/id_ed25519):
# Enter passphrase (empty for no passphrase):
# Your identification has been saved in /home/user/.ssh/id_ed25519
# Your public key has been saved in /home/user/.ssh/id_ed25519.pub
# The key fingerprint is:
# SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx your_email@example.com

# RSA の場合（4096ビット以上推奨）
ssh-keygen -t rsa -b 4096

# 公開鍵をサーバーに転送
ssh-copy-id -p 4242 user@server

# SSH 接続テスト
ssh -p 4242 kaztakam@localhost
# または（VirtualBox ポートフォワーディング経由）
ssh -p 4242 kaztakam@127.0.0.1
```

### 9.4 SSH の設定 (sshd_config)

サーバー側の SSH 設定ファイル: `/etc/ssh/sshd_config`

Born2beRoot で必要な設定:
```
Port 4242                    # デフォルトの 22 から変更
PermitRootLogin no           # root での SSH ログインを禁止
```

#### なぜ port 22 を変更するのか

デフォルトの port 22 は、インターネット上のボットネットによって常時スキャンされている。port を 4242 に変更すると:
- 自動化されたボットの大半は port 22 のみをスキャンするため、攻撃を回避できる
- ただし、nmap 等のポートスキャナーで全ポートをスキャンされれば発見される
- したがって、ポート変更は「多層防御」の一層に過ぎず、他の対策と組み合わせる必要がある

#### sshd_config の全パラメータ解説

```bash
# Born2beRoot 必須設定
Port 4242                      # 待ち受けポート
PermitRootLogin no             # root SSH ログイン禁止

# 推奨される追加設定（実務向け）
PasswordAuthentication yes     # パスワード認証（Born2beRoot ではyes）
PubkeyAuthentication yes       # 公開鍵認証
MaxAuthTries 3                 # 認証試行回数の制限
LoginGraceTime 30              # 認証のタイムアウト（秒）
ClientAliveInterval 300        # クライアント生存確認間隔（秒）
ClientAliveCountMax 2          # 生存確認の最大回数
X11Forwarding no               # X11フォワーディング無効
AllowUsers kaztakam            # 許可ユーザーの限定
Banner /etc/ssh/banner         # ログイン前バナー
```

```bash
# SSH 設定変更後のテスト手順
# 1. 設定ファイルの構文チェック
sudo sshd -t
# エラーがなければ何も表示されない

# 2. サービスの再起動
sudo systemctl restart sshd

# 3. 接続テスト（別のターミナルから）
ssh -p 4242 kaztakam@localhost

# 4. root ログインが拒否されることの確認
ssh -p 4242 root@localhost
# → Permission denied
```

---

## 10. sudo

### 10.1 sudo とは何か

**sudo (Superuser Do)** は、一般ユーザーが一時的に別のユーザー（通常は root）の権限でコマンドを実行するための仕組みである。

なぜ sudo が必要か:
- root で常時ログインするのは**危険**（操作ミスがシステム全体に影響）
- **最小権限の原則**: 必要な時だけ、必要な権限で操作する
- **監査可能性**: sudo は誰がいつ何を実行したかをログに記録する
- **細粒度の制御**: ユーザーごとに実行可能なコマンドを制限できる

### 10.2 sudoers ファイル

sudo の設定は `/etc/sudoers` ファイルで管理される。直接編集は危険なので、必ず `visudo` コマンドを使用する（構文チェック付き）。

```bash
# sudoers の編集（構文チェック付き）
sudo visudo

# sudoers.d ディレクトリの設定ファイルを編集
sudo visudo -f /etc/sudoers.d/sudo_config

# sudoers の構文:
# ユーザー ホスト=(実行ユーザー:実行グループ) コマンド
# 例:
# kaztakam ALL=(ALL:ALL) ALL
# → kaztakam は全ホストで全ユーザーとして全コマンドを実行可能

# グループ指定（% プレフィックス）
# %sudo ALL=(ALL:ALL) ALL
# → sudo グループの全メンバーに sudo 権限を付与
```

### 10.3 Born2beRoot の sudo 設定

`/etc/sudoers.d/sudo_config` に以下の設定を記述する:

```
Defaults  passwd_tries=3
Defaults  badpass_message="Wrong password. Access denied."
Defaults  logfile="/var/log/sudo/sudo.log"
Defaults  log_input
Defaults  log_output
Defaults  iolog_dir="/var/log/sudo"
Defaults  requiretty
Defaults  secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin"
```

各設定の詳細解説:

| 設定 | 値 | 説明 | 防ぐ攻撃 |
|------|---|------|---------|
| `passwd_tries` | 3 | パスワード試行回数の制限 | ブルートフォース |
| `badpass_message` | カスタム文字列 | 誤パスワード時のメッセージ | 情報漏洩防止 |
| `logfile` | /var/log/sudo/sudo.log | sudo コマンドのログファイル | 監査ログ |
| `log_input` | 有効 | 入力（キーストローク）の記録 | フォレンジック |
| `log_output` | 有効 | 出力の記録 | フォレンジック |
| `iolog_dir` | /var/log/sudo | I/O ログのディレクトリ | ログ管理 |
| `requiretty` | 有効 | TTY 必須 | Web Shell 対策 |
| `secure_path` | 指定パス | 安全な PATH | PATH 注入攻撃 |

#### requiretty が防ぐ攻撃シナリオ

```
TTY あり（正常なSSHセッション）:
  ユーザー → SSH → bash (TTY: /dev/pts/0) → sudo → OK

TTY なし（Web Shell）:
  攻撃者 → HTTP → PHP/CGI (TTY: なし) → sudo → DENIED (requiretty)

TTY なし（cron ジョブ）:
  cron → /bin/sh (TTY: なし) → sudo → DENIED (requiretty)
  ※ cron で sudo が必要な場合は root の crontab を使用
```

#### secure_path が防ぐ攻撃シナリオ

```
PATH 注入攻撃のシナリオ:

1. 攻撃者が悪意あるスクリプトを配置
   /home/user/ls (偽の ls コマンド)

2. ユーザーの PATH に /home/user を先頭に追加
   export PATH=/home/user:$PATH

3. secure_path なしで sudo ls を実行すると...
   → /home/user/ls が root 権限で実行される!

4. secure_path ありの場合
   → /usr/bin/ls が実行される（安全）
   sudo は secure_path で定義されたディレクトリのみを検索
```

```bash
# sudo ログの確認
cat /var/log/sudo/sudo.log
# 出力例:
# Jan 15 10:00:00 : kaztakam : TTY=pts/0 ; PWD=/home/kaztakam ;
#     USER=root ; COMMAND=/usr/bin/apt update

# I/O ログの再生
sudo sudoreplay -l
# 出力例:
# Jan 15 10:00:00 2024 : kaztakam : TTY=/dev/pts/0 ; CWD=/home/kaztakam ;
#     COMMAND=/usr/bin/apt update

sudo sudoreplay <session_id>
# 記録されたセッションを再生できる
```

---

## 11. systemd の詳細

### 11.1 systemd とは何か

systemd は現代の Linux ディストリビューションで標準的な init システムであり、PID 1 として動作する。

```
systemd の主な機能:

┌─────────────────────────────────────────────────────┐
│                     systemd                          │
│                                                      │
│  ┌────────────┐  ┌────────────┐  ┌───────────────┐  │
│  │ Service    │  │ Socket     │  │ Timer         │  │
│  │ Manager   │  │ Activation │  │ (cron の代替) │  │
│  │ (systemctl│  │            │  │               │  │
│  │  start/   │  │ (遅延起動) │  │ (秒単位の     │  │
│  │  stop/    │  │            │  │  精度)        │  │
│  │  enable)  │  │            │  │               │  │
│  └────────────┘  └────────────┘  └───────────────┘  │
│                                                      │
│  ┌────────────┐  ┌────────────┐  ┌───────────────┐  │
│  │ journald   │  │ logind     │  │ networkd      │  │
│  │ (ログ管理) │  │ (セッション│  │ (ネットワーク │  │
│  │            │  │  管理)     │  │  管理)        │  │
│  └────────────┘  └────────────┘  └───────────────┘  │
│                                                      │
│  ┌────────────┐  ┌────────────┐  ┌───────────────┐  │
│  │ udevd      │  │ tmpfiles   │  │ resolved      │  │
│  │ (デバイス  │  │ (一時ファイ│  │ (DNS リゾルバ)│  │
│  │  管理)     │  │  ル管理)   │  │               │  │
│  └────────────┘  └────────────┘  └───────────────┘  │
└─────────────────────────────────────────────────────┘
```

### 11.2 Unit ファイルの種類と構造

| 種類 | 拡張子 | 用途 | 例 |
|------|--------|------|-----|
| Service | `.service` | デーモンの管理 | ssh.service |
| Socket | `.socket` | ソケットベースの起動 | ssh.socket |
| Target | `.target` | ユニットのグループ化 | multi-user.target |
| Timer | `.timer` | 時間ベースの起動 | apt-daily.timer |
| Mount | `.mount` | ファイルシステムのマウント | home.mount |
| Path | `.path` | パスベースの起動 | cups.path |
| Slice | `.slice` | リソース管理グループ | user.slice |
| Scope | `.scope` | 外部プロセスの管理 | session-1.scope |

#### Unit ファイルの構造（ssh.service を例に）

```ini
[Unit]
Description=OpenBSD Secure Shell server
Documentation=man:sshd(8) man:sshd_config(5)
After=network.target auditd.service
ConditionPathExists=!/etc/ssh/sshd_not_to_be_run

[Service]
EnvironmentFile=-/etc/default/ssh
ExecStartPre=/usr/sbin/sshd -t
ExecStart=/usr/sbin/sshd -D $SSHD_OPTS
ExecReload=/bin/kill -HUP $MAINPID
KillMode=process
Restart=on-failure
RestartPreventExitStatus=255
Type=notify
RuntimeDirectory=sshd
RuntimeDirectoryMode=0755

[Install]
WantedBy=multi-user.target
```

各セクションの詳細:

```
[Unit] セクション:
  Description   - サービスの説明
  Documentation - マニュアルの参照先
  After         - このユニットの後に起動するユニット
  Before        - このユニットの前に起動するユニット
  Requires      - 必須依存関係（失敗すると自身も失敗）
  Wants         - 推奨依存関係（失敗しても自身は起動）
  Conflicts     - 競合するユニット（同時起動不可）
  ConditionPathExists - 指定パスの存在チェック

[Service] セクション:
  Type          - サービスの起動タイプ
                  simple:  ExecStart のプロセスがメインプロセス
                  forking: デーモンがフォークして親が終了
                  oneshot: 一度実行して終了
                  notify:  sd_notify() で準備完了を通知
  ExecStartPre  - 起動前に実行するコマンド
  ExecStart     - メインの起動コマンド
  ExecStartPost - 起動後に実行するコマンド
  ExecStop      - 停止コマンド
  ExecReload    - 再読み込みコマンド
  Restart       - 再起動ポリシー (always, on-failure, etc.)
  RestartSec    - 再起動までの待ち時間
  KillMode      - プロセス終了方法
  Environment   - 環境変数
  EnvironmentFile - 環境変数ファイル
  User/Group    - 実行ユーザー/グループ
  WorkingDirectory - 作業ディレクトリ

[Install] セクション:
  WantedBy      - enable 時にこのターゲットに追加
  RequiredBy    - enable 時にこのターゲットの必須として追加
  Alias         - ユニットの別名
```

### 11.3 systemctl コマンドの全サブコマンド

```bash
# === サービスの基本操作 ===
sudo systemctl start sshd          # サービスの起動
sudo systemctl stop sshd           # サービスの停止
sudo systemctl restart sshd        # 再起動（stop→start）
sudo systemctl reload sshd         # 設定の再読み込み（サービスを停止しない）
sudo systemctl try-restart sshd    # 実行中のみ再起動

# === 自動起動設定 ===
sudo systemctl enable sshd         # ブート時に自動起動
sudo systemctl disable sshd        # 自動起動を無効化
sudo systemctl enable --now sshd   # 有効化して即座に起動
sudo systemctl is-enabled sshd     # 自動起動の設定確認
# 出力: enabled / disabled

# === 状態確認 ===
systemctl status sshd              # 詳細な状態表示
systemctl is-active sshd           # アクティブかどうか
systemctl is-failed sshd           # 失敗しているかどうか
systemctl show sshd                # 全プロパティ表示
systemctl show sshd -p MainPID     # 特定プロパティ表示

# === ユニットの一覧 ===
systemctl list-units                        # 全ユニット
systemctl list-units --type=service         # サービスのみ
systemctl list-units --state=running        # 実行中のみ
systemctl list-units --state=failed         # 失敗したもの
systemctl list-unit-files                   # 全ユニットファイル
systemctl list-unit-files --type=service    # サービスファイル
systemctl list-dependencies sshd            # 依存関係ツリー

# === ユニットファイルの操作 ===
systemctl cat sshd                 # ユニットファイルの内容表示
systemctl edit sshd                # ドロップインファイルの編集
systemctl edit --full sshd         # ユニットファイル全体の編集
systemctl daemon-reload            # ユニットファイル変更の反映

# === システム全体 ===
systemctl get-default              # デフォルトターゲット
# 出力: multi-user.target（GUIなし）
# 出力: graphical.target（GUIあり）

sudo systemctl set-default multi-user.target  # GUIなしに設定
systemctl isolate multi-user.target           # 即座にターゲット変更

# === 電源管理 ===
sudo systemctl reboot              # 再起動
sudo systemctl poweroff            # シャットダウン
sudo systemctl halt                # 停止（電源オフなし）
sudo systemctl suspend             # サスペンド
sudo systemctl hibernate           # ハイバネート
```

### 11.4 systemd の依存関係

```
Born2beRoot の起動依存関係ツリー:

default.target (multi-user.target)
│
├── basic.target
│   ├── sysinit.target
│   │   ├── local-fs.target
│   │   │   ├── -.mount (ルートFS)
│   │   │   ├── boot.mount (/boot)
│   │   │   ├── home.mount (/home)
│   │   │   ├── var.mount (/var)
│   │   │   ├── var-log.mount (/var/log)
│   │   │   ├── srv.mount (/srv)
│   │   │   └── tmp.mount (/tmp)
│   │   ├── swap.target
│   │   │   └── dev-LVMGroup-swap.swap
│   │   ├── cryptsetup.target
│   │   │   └── systemd-cryptsetup@sda5_crypt.service
│   │   └── lvm2-activation.service
│   │
│   ├── sockets.target
│   └── timers.target
│
├── network.target
│   └── networking.service
│       → DHCP で IP アドレス取得
│
├── ssh.service
│   After: network.target
│   → port 4242 で LISTEN 開始
│
├── cron.service
│   → monitoring.sh を 10 分ごとに実行
│
├── ufw.service (iptables ルールのロード)
│   → port 4242 のみ ALLOW
│
├── apparmor.service
│   → プロファイルのロード
│
└── getty@tty1.service
    → ログインプロンプト表示
```

### 11.5 ジャーナルログ (journald)

systemd は **journald** でログを管理する。従来の syslog と異なり、構造化されたバイナリ形式でログを保存する。

```bash
# 全ログの表示
journalctl

# 特定サービスのログ
journalctl -u sshd
journalctl -u ssh.service

# 最近のログ（末尾N行）
journalctl -n 50

# リアルタイムでログを監視
journalctl -f

# 特定のコマンドのログ
journalctl _COMM=sudo

# 時間範囲指定
journalctl --since "2024-01-15 10:00:00" --until "2024-01-15 11:00:00"
journalctl --since "1 hour ago"
journalctl --since today

# 優先度でフィルタ
journalctl -p err    # error 以上のみ
# 優先度: emerg(0), alert(1), crit(2), err(3),
#         warning(4), notice(5), info(6), debug(7)

# ブートごとのログ
journalctl -b         # 現在のブート
journalctl -b -1      # 前回のブート
journalctl --list-boots  # ブート一覧

# 出力フォーマット
journalctl -o json         # JSON 形式
journalctl -o json-pretty  # 整形された JSON
journalctl -o verbose      # 全フィールド表示
journalctl -o short-iso    # ISO 8601 タイムスタンプ

# ディスク使用量の確認
journalctl --disk-usage
# 出力例: Archived and active journals take up 48.0M in the file system.

# 古いログの削除
sudo journalctl --vacuum-time=7d    # 7日以前を削除
sudo journalctl --vacuum-size=100M  # 100MB に制限
```

---

## 12. AppArmor と SELinux

### 12.1 Linux のアクセス制御の全体像

Linux のセキュリティモデルは3つの層で構成される:

```
┌──────────────────────────────────────────┐
│  Layer 3: Linux Security Modules (LSM)   │
│  ┌─────────────┐  ┌──────────────┐       │
│  │  AppArmor   │  │   SELinux    │       │
│  │(パスベースMAC)│  │(ラベルベースMAC)│    │
│  └─────────────┘  └──────────────┘       │
├──────────────────────────────────────────┤
│  Layer 2: Capabilities                   │
│  (root権限を細分化した約40の権限)        │
│  CAP_NET_BIND_SERVICE: 1024未満のポート  │
│  CAP_SYS_ADMIN: システム管理操作          │
│  CAP_DAC_OVERRIDE: DACバイパス           │
│  CAP_CHOWN: ファイル所有者変更           │
│  CAP_NET_RAW: rawソケット作成            │
├──────────────────────────────────────────┤
│  Layer 1: DAC (Discretionary AC)         │
│  (従来のパーミッション: rwx, UID/GID)   │
│  chmod, chown, umask                     │
└──────────────────────────────────────────┘
```

### 12.2 AppArmor

**AppArmor** は Debian/Ubuntu でデフォルトで使用される MAC システムである。

```bash
# AppArmor の状態確認
sudo aa-status
# 出力例:
# apparmor module is loaded.
# 38 profiles are loaded.
# 36 profiles are in enforce mode.
#    /usr/bin/man
#    /usr/sbin/sshd
#    ...
# 2 profiles are in complain mode.
# 0 profiles are in kill mode.
# 0 profiles are in unconfined mode.
# 5 processes have profiles defined.
# 5 processes are in enforce mode.

# プロファイルの操作
sudo aa-enforce /etc/apparmor.d/usr.sbin.sshd    # enforce モード
sudo aa-complain /etc/apparmor.d/usr.sbin.sshd   # complain モード
sudo aa-disable /etc/apparmor.d/usr.sbin.sshd    # 無効化

# AppArmor のログ確認
sudo journalctl -k | grep apparmor
# または
cat /var/log/syslog | grep apparmor
```

AppArmor プロファイルの例（sshd）:
```
# /etc/apparmor.d/usr.sbin.sshd
/usr/sbin/sshd {
  # ネットワークアクセス
  network inet stream,
  network inet6 stream,

  # 読み取り可能なファイル
  /etc/ssh/** r,
  /etc/passwd r,
  /etc/shadow r,
  /etc/nsswitch.conf r,

  # 書き込み可能なファイル
  /var/log/auth.log w,
  /run/sshd.pid w,

  # 実行可能なプログラム
  /usr/sbin/sshd mr,
  /bin/bash px,

  # 拒否される操作（ポリシーに記載されていない操作は全て拒否）
  # → sshd が /home/user/.bash_history を読み取ろうとすると拒否
}
```

### 12.3 SELinux

**SELinux (Security-Enhanced Linux)** は Red Hat/Rocky Linux でデフォルトで使用される MAC システムである。

### 12.4 AppArmor vs SELinux

| 項目 | AppArmor | SELinux |
|------|----------|---------|
| アプローチ | パスベース | ラベルベース |
| 複雑さ | シンプル | 複雑 |
| デフォルト OS | Debian/Ubuntu | RHEL/Rocky/Fedora |
| 学習コスト | 低い | 高い |
| 柔軟性 | 中程度 | 非常に高い |
| ポリシー適用範囲 | プログラム単位 | システム全体 |
| ファイル移動時 | パスが変わればポリシーも変わる | ラベルはファイルに付随する |

---

## 13. cron

### 13.1 cron とは何か

**cron** は、Unix/Linux システムでタスクを定期的に自動実行するためのデーモン（バックグラウンドプロセス）である。

### 13.2 crontab の書式

```
*     *     *     *     *    command
┬     ┬     ┬     ┬     ┬
│     │     │     │     │
│     │     │     │     └─── 曜日 (0-7, 0と7は日曜)
│     │     │     └───────── 月 (1-12)
│     │     └─────────────── 日 (1-31)
│     └───────────────────── 時 (0-23)
└─────────────────────────── 分 (0-59)

特殊文字:
  *    : 全ての値にマッチ
  */n  : n 間隔（例: */10 = 0,10,20,30,40,50）
  n,m  : n と m の両方にマッチ
  n-m  : n から m の範囲にマッチ
  n-m/s: n から m の範囲で s 間隔

例:
  */10 * * * *           10分ごと（0,10,20,30,40,50分）
  0 * * * *              毎時0分
  0 0 * * *              毎日0時0分
  0 0 * * 0              毎週日曜0時0分
  0 0 1 * *              毎月1日0時0分
  30 2 * * 1-5           平日の2:30
  0 */6 * * *            6時間ごと
```

### 13.3 Born2beRoot での cron 設定

```bash
# root の crontab を編集
sudo crontab -e

# 以下を追加:
*/10 * * * * /usr/local/bin/monitoring.sh

# crontab の確認
sudo crontab -l
# 出力: */10 * * * * /usr/local/bin/monitoring.sh

# cron ジョブの動作確認
# 1. 手動実行テスト
sudo /usr/local/bin/monitoring.sh

# 2. cron ログの確認
grep CRON /var/log/syslog
# または
journalctl -u cron

# cron サービスの状態確認
sudo systemctl status cron
```

### 13.4 systemd timer との比較

| 項目 | cron | systemd timer |
|------|------|--------------|
| 設定方法 | crontab | .timer + .service ファイル |
| ログ | 独自ログ | journald に統合 |
| 依存関係 | なし | systemd の依存関係管理 |
| 精度 | 分単位 | マイクロ秒単位 |
| リソース制御 | なし | cgroups で制御可能 |
| 起動漏れ | 停止中は実行されない | Persistent=true で次回実行 |

---

## 14. wall コマンド

**wall (Write All)** は、現在ログインしている全てのユーザーの端末にメッセージをブロードキャストするコマンドである。

```bash
# 直接メッセージを送信
wall "System maintenance in 5 minutes"

# パイプで送信（monitoring.sh で使用するパターン）
echo "message" | wall

# ファイルから送信
wall < /path/to/message_file
```

monitoring.sh では、収集したシステム情報を wall コマンドで全端末に表示する。

---

## 15. パスワードポリシー

### 15.1 なぜパスワードポリシーが重要か

弱いパスワードはシステムセキュリティの最大の脅威の一つである:

- **ブルートフォース攻撃**: 全ての組み合わせを試行する攻撃
- **辞書攻撃**: 一般的な単語やフレーズのリストを使った攻撃
- **レインボーテーブル攻撃**: 事前計算されたハッシュテーブルを使った攻撃
- **クレデンシャルスタッフィング**: 他サービスで漏洩したパスワードを使った攻撃

### 15.2 パスワードの強度 - エントロピーの数学

パスワードの強度は**エントロピー**（情報量、ビット単位）で測定される:

```
エントロピー = log2(文字種^文字数)

文字種ごとのエントロピー:
  小文字のみ (26文字):        log2(26) ≈ 4.7 bits/文字
  小文字+大文字 (52文字):      log2(52) ≈ 5.7 bits/文字
  小文字+大文字+数字 (62文字): log2(62) ≈ 5.95 bits/文字
  上記+記号 (95文字):          log2(95) ≈ 6.57 bits/文字

Born2beRoot のポリシー（10文字、大小+数字）:
  エントロピー ≈ 10 x 5.95 ≈ 59.5 bits
  → オフラインブルートフォース（毎秒10億試行）: 約26年
```

### 15.3 PAM (Pluggable Authentication Modules) フレームワーク

```
PAM の動作フロー（パスワード変更時）:

ユーザーが passwd コマンドを実行
    │
    ▼
PAM スタック (/etc/pam.d/common-password):
    │
    ├── pam_pwquality.so      ← パスワード品質チェック
    │   minlen=10             最小10文字
    │   ucredit=-1            大文字1文字以上
    │   lcredit=-1            小文字1文字以上
    │   dcredit=-1            数字1文字以上
    │   maxrepeat=3           連続同一文字3以下
    │   reject_username       ユーザー名を含まない
    │   difok=7               旧パスワードと7文字以上異なる
    │   enforce_for_root      root にも適用
    │
    ├── pam_unix.so           ← パスワードハッシュ化・保存
    │   sha512                SHA-512 ハッシュ
    │   shadow                /etc/shadow に保存
    │   use_authtok           前のモジュールのトークンを使用
    │
    └── 結果を passwd に返す
```

### 15.4 Born2beRoot のパスワードポリシー設定

**パスワードの有効期限** (`/etc/login.defs`):
```
PASS_MAX_DAYS   30    # パスワードの有効期限: 30日
PASS_MIN_DAYS   2     # パスワード変更の最小間隔: 2日
PASS_WARN_AGE   7     # 有効期限の 7日前に警告
```

**パスワードの強度** (`/etc/pam.d/common-password`):
```
password requisite pam_pwquality.so retry=3 \
    minlen=10 ucredit=-1 dcredit=-1 lcredit=-1 \
    maxrepeat=3 reject_username difok=7 enforce_for_root
```

### 15.5 既存ユーザーへのポリシー適用

```bash
# /etc/login.defs の変更は新規ユーザーにのみ適用される
# 既存ユーザーには chage コマンドで個別に設定:

sudo chage -M 30 kaztakam     # 最大有効期限 30日
sudo chage -m 2 kaztakam      # 最小変更間隔 2日
sudo chage -W 7 kaztakam      # 警告 7日前

# root にも適用
sudo chage -M 30 root
sudo chage -m 2 root
sudo chage -W 7 root

# 設定の確認
sudo chage -l kaztakam
# 出力例:
# Last password change                    : Jan 15, 2024
# Password expires                        : Feb 14, 2024
# Password inactive                       : never
# Account expires                         : never
# Minimum number of days between password change : 2
# Maximum number of days between password change : 30
# Number of days of warning before password expires : 7
```

---

## 16. apt vs aptitude

### 16.1 apt vs aptitude の違い

| 項目 | apt | aptitude |
|------|-----|----------|
| インターフェース | コマンドラインのみ | コマンドライン + TUI (テキストUI) |
| 依存関係解決 | 基本的な解決（1つの候補） | より高度な解決（複数の候補を提示） |
| 未使用パッケージ | 手動で `apt autoremove` | 自動的に削除を提案 |
| 推奨パッケージ | デフォルトでインストール | デフォルトでインストールしない |
| インストール | デフォルトで含まれる | 追加インストールが必要 |
| 速度 | やや速い | やや遅い |

重要な違い: aptitude は依存関係の競合が発生した場合、複数の解決策を提案して選択させる。apt は単一の解決策を適用するか失敗する。

---

## 17. カーネルモジュール

Born2beRoot で関連するカーネルモジュール:

| モジュール | 用途 | Born2beRoot での役割 |
|-----------|------|---------------------|
| `dm-crypt` | ディスク暗号化 | LUKS 暗号化の実装 |
| `dm-mod` | Device Mapper | LVM の基盤 |
| `nf_tables` / `ip_tables` | パケットフィルタリング | UFW / iptables の基盤 |
| `apparmor` | MAC セキュリティ | AppArmor の実装 |
| `ext4` | ファイルシステム | メインのファイルシステム |
| `aes_x86_64` / `aesni_intel` | AES ハードウェアアクセラレーション | LUKS の高速暗号化 |

```bash
# ロードされたモジュールの一覧
lsmod
# 出力例:
# Module                  Size  Used by
# dm_crypt               45056  1
# dm_mod                126976  5 dm_crypt,dm_log,...
# nf_tables              98304  1
# ip_tables              28672  1
# apparmor              126976  5
# ext4                  745472  4

# 特定のモジュールの情報
modinfo dm_crypt
# 出力例:
# filename:       /lib/modules/5.10.0-XX/kernel/drivers/md/dm-crypt.ko
# license:        GPL
# description:    device-mapper target for transparent encryption
# author:         Jana Saout <jana@saout.de>
# depends:        dm-mod

# モジュールのロード
sudo modprobe dm_crypt

# モジュールのアンロード
sudo modprobe -r dm_crypt

# モジュールの依存関係確認
modprobe --show-depends dm_crypt
```

---

## 18. コンテナ仮想化との比較

### 18.1 仮想マシン vs コンテナ

Born2beRoot では VM（仮想マシン）を使用するが、現代のインフラではコンテナ技術（Docker, Kubernetes）も広く使用されている。両者の違いを理解することは重要である。

```
仮想マシン (VM):
┌─────────────┐ ┌─────────────┐ ┌─────────────┐
│  App A      │ │  App B      │ │  App C      │
├─────────────┤ ├─────────────┤ ├─────────────┤
│  Bins/Libs  │ │  Bins/Libs  │ │  Bins/Libs  │
├─────────────┤ ├─────────────┤ ├─────────────┤
│  Guest OS   │ │  Guest OS   │ │  Guest OS   │
│  (完全なOS) │ │  (完全なOS) │ │  (完全なOS) │
├─────────────┴─┴─────────────┴─┴─────────────┤
│              Hypervisor                       │
├───────────────────────────────────────────────┤
│            Host OS / Hardware                 │
└───────────────────────────────────────────────┘

コンテナ:
┌─────────────┐ ┌─────────────┐ ┌─────────────┐
│  App A      │ │  App B      │ │  App C      │
├─────────────┤ ├─────────────┤ ├─────────────┤
│  Bins/Libs  │ │  Bins/Libs  │ │  Bins/Libs  │
├─────────────┴─┴─────────────┴─┴─────────────┤
│           Container Runtime (Docker)          │
├───────────────────────────────────────────────┤
│              Host OS (共有カーネル)            │
├───────────────────────────────────────────────┤
│              Hardware                         │
└───────────────────────────────────────────────┘

主な違い:
  VM: 各VMが完全なOSを持つ → 重い（GB単位）、起動に分単位
  コンテナ: ホストのカーネルを共有 → 軽い（MB単位）、起動に秒単位
```

| 特徴 | 仮想マシン | コンテナ |
|------|----------|---------|
| 分離レベル | ハードウェアレベル | OS レベル |
| カーネル | 各 VM が独自のカーネル | ホストのカーネルを共有 |
| サイズ | GB 単位（OS 込み） | MB 単位（アプリ + ライブラリのみ） |
| 起動時間 | 分単位 | 秒単位 |
| パフォーマンス | ハイパーバイザーのオーバーヘッド | ほぼネイティブ |
| セキュリティ | 強い分離（異なるカーネル） | 弱い分離（カーネル共有） |
| ユースケース | 異なる OS の実行、強い分離 | マイクロサービス、CI/CD |

### 18.2 コンテナの分離技術

コンテナは Linux カーネルの2つの機能で分離を実現する:

#### Namespace（名前空間）

```
Linux Namespace の種類:

┌─────────────────────────────────────────────────────────┐
│  PID Namespace（プロセスID）                             │
│  コンテナ内のプロセスは PID 1 から始まる                 │
│  ホストの他のプロセスは見えない                           │
│                                                          │
│  ホスト:     PID 1(systemd) → PID 100(docker) → ...    │
│  コンテナA:  PID 1(init)    → PID 2(app)      → ...    │
│  コンテナB:  PID 1(init)    → PID 2(app)      → ...    │
├─────────────────────────────────────────────────────────┤
│  NET Namespace（ネットワーク）                            │
│  コンテナごとに独立したネットワークスタック               │
│  独自の IP アドレス、ルーティングテーブル                 │
│  veth ペアでホストのブリッジに接続                        │
├─────────────────────────────────────────────────────────┤
│  MNT Namespace（マウント）                               │
│  コンテナごとに独立したファイルシステムビュー             │
│  ホストのファイルシステムは見えない                       │
├─────────────────────────────────────────────────────────┤
│  UTS Namespace（ホスト名）                               │
│  コンテナごとに独自のホスト名                             │
├─────────────────────────────────────────────────────────┤
│  IPC Namespace（プロセス間通信）                          │
│  共有メモリ、セマフォ等の分離                             │
├─────────────────────────────────────────────────────────┤
│  USER Namespace（ユーザーID）                             │
│  コンテナ内の root がホストでは一般ユーザーにマッピング  │
│  コンテナ: UID 0 (root) → ホスト: UID 100000            │
└─────────────────────────────────────────────────────────┘
```

#### cgroups（コントロールグループ）

```
cgroups によるリソース制限:

┌──────────────────────────────────────────────┐
│  CPU 制限                                     │
│  コンテナ A: CPU 50% まで                    │
│  コンテナ B: CPU 30% まで                    │
│  残り 20%: ホストとその他のプロセス          │
├──────────────────────────────────────────────┤
│  メモリ制限                                   │
│  コンテナ A: 最大 512 MB                     │
│  コンテナ B: 最大 256 MB                     │
│  超過時: OOM Killer が発動                   │
├──────────────────────────────────────────────┤
│  I/O 制限                                     │
│  ディスク読み書きの帯域幅を制限               │
├──────────────────────────────────────────────┤
│  ネットワーク帯域                             │
│  送受信の帯域幅を制限                         │
└──────────────────────────────────────────────┘
```

### 18.3 なぜ Born2beRoot で VM を使うのか

Born2beRoot では以下の理由から、コンテナではなく VM を使用する:

1. **完全な OS の学習**: VM では OS のインストールからカーネルの設定まで全てを経験できる
2. **ブートプロセスの理解**: GRUB、initramfs、systemd のブートチェーンを体験できる
3. **LUKS 暗号化**: ディスク全体の暗号化はコンテナでは実現困難
4. **カーネルレベルの操作**: カーネルモジュール、sysctl の設定が直接行える
5. **ネットワークの完全な制御**: ファイアウォール（UFW/iptables）の設定が独立して行える
6. **強い分離**: セキュリティ学習において、強い分離を持つ VM が適切

---

## 19. プロセス管理

### 19.1 プロセスの基本概念

Linux ではプログラムの実行単位を**プロセス**と呼ぶ。各プロセスは一意の PID (Process ID) を持つ。

```
プロセスの階層構造:

PID 1: systemd (init)
├── PID 100: systemd-journald (ログ管理)
├── PID 150: systemd-udevd (デバイス管理)
├── PID 200: sshd (SSH デーモン)
│   └── PID 300: sshd (接続セッション)
│       └── PID 301: bash (ユーザーシェル)
│           ├── PID 400: vim (エディタ)
│           └── PID 401: grep (検索)
├── PID 250: cron (タスクスケジューラ)
│   └── PID 500: monitoring.sh (10分ごと)
│       └── PID 501: wall (ブロードキャスト)
└── PID 350: ufw (ファイアウォール)
```

### 19.2 プロセスの状態

```
プロセスの状態遷移:

                   fork()
        ┌──────────────────────┐
        │                      ▼
    ┌───────┐              ┌───────┐
    │Created│──────────────│Running│
    └───────┘   schedule   └───┬───┘
                               │
                    ┌──────────┼──────────┐
                    │          │          │
                    ▼          ▼          ▼
              ┌─────────┐ ┌───────┐ ┌────────┐
              │Sleeping │ │Stopped│ │ Zombie │
              │(I/O wait)│ │(^Z)  │ │(defunct)│
              └────┬────┘ └───┬───┘ └────┬───┘
                   │          │          │
                   │    cont  │   parent │
                   └──────────┘   wait() │
                       │                 │
                       ▼                 ▼
                  ┌───────┐         ┌───────┐
                  │Running│         │Removed│
                  └───────┘         └───────┘

ps aux の STATE 列:
  R: Running     実行中 / 実行待ち
  S: Sleeping    割り込み可能なスリープ（I/O待ち等）
  D: Disk sleep  割り込み不可のスリープ（ディスクI/O）
  T: Stopped     停止（Ctrl+Z, SIGSTOP）
  Z: Zombie      終了したが親がwait()していない
  I: Idle        カーネルスレッドのアイドル
```

### 19.3 プロセス管理コマンド

```bash
# プロセスの一覧表示
ps aux
# 出力:
# USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
# root         1  0.0  0.8 169104 12500 ?        Ss   10:00   0:01 /sbin/init
# root       200  0.0  0.3  15124  4520 ?        Ss   10:00   0:00 sshd
# kaztakam   301  0.0  0.2   9176  3820 pts/0    Ss   10:05   0:00 -bash

# 各カラムの意味:
# USER: プロセスの実行ユーザー
# PID:  プロセスID
# %CPU: CPU 使用率
# %MEM: メモリ使用率
# VSZ:  仮想メモリサイズ (KB)
# RSS:  実際に使用中の物理メモリ (KB)
# TTY:  制御端末（? = デーモン）
# STAT: プロセスの状態
# START: 起動時刻
# TIME:  累積CPU時間
# COMMAND: 実行コマンド

# プロセスツリーの表示
pstree -p
# systemd(1)─┬─cron(250)
#             ├─sshd(200)─┬─sshd(300)───bash(301)
#             │            └─sshd(310)───bash(311)
#             └─systemd-journal(100)

# リアルタイムモニタリング
top
# q: 終了
# P: CPU使用率でソート
# M: メモリ使用率でソート
# k: プロセスの kill

# プロセスの終了
kill PID           # SIGTERM (15) を送信（正常終了要求）
kill -9 PID        # SIGKILL (9) を送信（強制終了）
kill -STOP PID     # SIGSTOP を送信（一時停止）
kill -CONT PID     # SIGCONT を送信（再開）

# プロセスの検索
pgrep sshd         # sshd のPIDを検索
pkill firefox      # firefox プロセスを終了

# バックグラウンド実行
command &           # バックグラウンドで実行
jobs               # バックグラウンドジョブの一覧
fg %1              # ジョブ1をフォアグラウンドに
bg %1              # ジョブ1をバックグラウンドに
```

### 19.4 シグナル一覧

```
主要なシグナル:

シグナル番号  名前      動作                     用途
──────────────────────────────────────────────────────────
    1       SIGHUP    終了                     デーモンの設定再読み込み
    2       SIGINT    終了                     Ctrl+C（割り込み）
    3       SIGQUIT   コアダンプ付き終了       Ctrl+\
    9       SIGKILL   強制終了                 プロセスの強制停止
   15       SIGTERM   終了                     正常終了要求（デフォルト）
   18       SIGCONT   再開                     停止したプロセスの再開
   19       SIGSTOP   停止                     プロセスの一時停止
   20       SIGTSTP   停止                     Ctrl+Z（端末からの停止）

SIGTERM vs SIGKILL:
  SIGTERM (15):
    → プロセスがシグナルをキャッチして後処理（ファイルの保存、
      一時ファイルの削除等）を行ってから終了可能
    → プロセスがシグナルを無視する可能性がある
    → 推奨: まず SIGTERM を試す

  SIGKILL (9):
    → プロセスがキャッチ・無視できない
    → カーネルが直接プロセスを終了
    → 後処理が行われない（データ損失の可能性）
    → SIGTERM で終了しない場合の最後の手段
```

---

## 20. ユーザーとグループの管理

### 20.1 ユーザー管理の基本

Linux ではユーザー情報は以下のファイルで管理される:

```
/etc/passwd - ユーザー情報（全ユーザーが読み取り可能）
─────────────────────────────────────────────────────
kaztakam:x:1000:1000:Kaztakam:/home/kaztakam:/bin/bash
   │     │  │    │      │         │            │
   │     │  │    │      │         │            └─ ログインシェル
   │     │  │    │      │         └────────────── ホームディレクトリ
   │     │  │    │      └──────────────────────── コメント（GECOS フィールド）
   │     │  │    └─────────────────────────────── プライマリGID
   │     │  └──────────────────────────────────── UID
   │     └─────────────────────────────────────── パスワード（x = /etc/shadow参照）
   └───────────────────────────────────────────── ユーザー名

/etc/shadow - パスワードハッシュ（root のみ読み取り可能）
─────────────────────────────────────────────────────
kaztakam:$6$rounds=5000$salt$hash:19738:2:30:7:::
   │         │                    │    │  │  │
   │         │                    │    │  │  └─── 警告日数 (WARN_AGE)
   │         │                    │    │  └────── 最大日数 (MAX_DAYS)
   │         │                    │    └───────── 最小日数 (MIN_DAYS)
   │         │                    └────────────── 最終変更日
   │         └─────────────────────────────────── パスワードハッシュ
   └───────────────────────────────────────────── ユーザー名

/etc/group - グループ情報
─────────────────────────────────────────────────────
sudo:x:27:kaztakam
 │   │ │      │
 │   │ │      └─── グループメンバー（カンマ区切り）
 │   │ └────────── GID
 │   └──────────── パスワード（x = /etc/gshadow参照）
 └──────────────── グループ名
```

### 20.2 UID/GID の体系

```
UID の割り当て規則（Debian）:

  UID 0:         root（スーパーユーザー）
  UID 1-99:      システムユーザー（Debian が予約）
  UID 100-999:   動的割り当てシステムユーザー
  UID 1000-:     一般ユーザー（adduser で作成）
  UID 65534:     nobody（権限を最小限にしたユーザー）

GID の割り当て規則:
  GID 0:         root グループ
  GID 1-99:      システムグループ
  GID 100-999:   動的割り当てシステムグループ
  GID 1000-:     一般グループ
  GID 27:        sudo グループ（Debian のデフォルト）

Born2beRoot で重要なグループ:
  sudo (GID 27):   sudo コマンドの実行が許可される
  user42:           プロジェクト要件のカスタムグループ
```

### 20.3 ユーザー管理コマンド

```bash
# ユーザーの作成
sudo adduser newuser
# 対話的にパスワード、フルネーム等を設定
# /home/newuser を自動作成
# /etc/skel の内容をコピー

# useradd との違い:
# adduser: Debian の高レベルコマンド（対話的、推奨）
# useradd: 低レベルコマンド（スクリプト用）
# useradd はホームディレクトリを作成しない場合がある

# ユーザーの削除
sudo deluser newuser              # ユーザーのみ削除
sudo deluser --remove-home newuser # ホームディレクトリも削除

# グループの作成
sudo groupadd user42

# グループへの追加
sudo usermod -aG sudo newuser     # sudo グループに追加
sudo usermod -aG user42 newuser   # user42 グループに追加
# -a: 追加モード（これがないと既存グループから外れる！）
# -G: 補助グループの指定

# !!!警告!!!
# sudo usermod -G user42 newuser  ← -a を忘れると
# → sudo グループから外れる（-a なしは置き換え動作）

# グループからの削除
sudo gpasswd -d newuser user42

# ユーザー情報の確認
id newuser
# uid=1001(newuser) gid=1001(newuser) groups=1001(newuser),27(sudo),1002(user42)

# グループの確認
groups newuser
# newuser : newuser sudo user42

# 全グループの一覧
getent group
# root:x:0:
# sudo:x:27:kaztakam,newuser
# user42:x:1002:kaztakam,newuser

# パスワードの変更
sudo passwd newuser

# パスワード有効期限の設定
sudo chage -M 30 -m 2 -W 7 newuser
```

---

## 21. ファイルパーミッションの深層

### 21.1 パーミッションビットの構造

```
ls -l の出力の解読:

-rwxr-xr-- 1 kaztakam sudo 4096 Jan 15 10:00 script.sh
│││││││││     │        │     │         │           │
│││││││││     │        │     │         │           └ ファイル名
│││││││││     │        │     │         └──────────── 更新日時
│││││││││     │        │     └────────────────────── サイズ (bytes)
│││││││││     │        └──────────────────────────── グループ
│││││││││     └───────────────────────────────────── 所有者
│││││││││
│├┤├┤├┤
││││││└── その他 (others): r-- (4)
│││││└─── その他 (others): r (4)
││││└──── グループ (group): r-x (5)
│││└───── グループ (group): r (4)
││└────── グループ (group): x (1)
│└─────── 所有者 (owner): rwx (7)
└──────── ファイルタイプ (- = 通常, d = ディレクトリ, l = シンボリックリンク)

パーミッションのビット表現:
  r (read)    = 4 (100)
  w (write)   = 2 (010)
  x (execute) = 1 (001)

  rwx = 4+2+1 = 7
  r-x = 4+0+1 = 5
  r-- = 4+0+0 = 4

  chmod 754 script.sh
  → owner: rwx (7), group: r-x (5), others: r-- (4)

パーミッションの意味:
  ファイルの場合:
    r: ファイルの内容を読み取り可能
    w: ファイルの内容を変更可能
    x: ファイルを実行可能

  ディレクトリの場合:
    r: ディレクトリ内のファイル一覧を表示可能
    w: ディレクトリ内のファイルを作成・削除可能
    x: ディレクトリに cd で移動可能（ファイルにアクセス可能）
```

### 21.2 特殊パーミッション

```
特殊パーミッションビット:

SUID (Set User ID) - 4000:
  ┌──────────────────────────────────────────┐
  │  ファイルの所有者の権限で実行される       │
  │  代表例: /usr/bin/passwd                  │
  │    -rwsr-xr-x 1 root root ... /usr/bin/passwd │
  │      ^                                    │
  │      s = SUID ビット                      │
  │                                           │
  │  passwd は /etc/shadow を変更するため     │
  │  root 権限が必要。SUID により一般ユーザー │
  │  でも root として実行される               │
  └──────────────────────────────────────────┘

SGID (Set Group ID) - 2000:
  ┌──────────────────────────────────────────┐
  │  ファイル: グループの権限で実行される     │
  │  ディレクトリ: 作成されるファイルが       │
  │  ディレクトリのグループを継承する         │
  │                                           │
  │  drwxrwsr-x 2 root staff ... /shared/     │
  │         ^                                 │
  │         s = SGID ビット                   │
  │                                           │
  │  /shared/ 内に作成されるファイルは         │
  │  自動的に staff グループになる            │
  └──────────────────────────────────────────┘

Sticky Bit - 1000:
  ┌──────────────────────────────────────────┐
  │  ディレクトリ内のファイルは所有者のみ     │
  │  削除・リネーム可能                       │
  │  代表例: /tmp                             │
  │                                           │
  │  drwxrwxrwt 10 root root ... /tmp          │
  │           ^                               │
  │           t = Sticky Bit                  │
  │                                           │
  │  /tmp は全ユーザーが書き込み可能だが、    │
  │  Sticky Bit により他人のファイルを削除不可│
  └──────────────────────────────────────────┘

設定方法:
  chmod 4755 file   # SUID + rwxr-xr-x
  chmod 2755 dir    # SGID + rwxr-xr-x
  chmod 1777 dir    # Sticky + rwxrwxrwx

  chmod u+s file    # SUID をシンボリックモードで設定
  chmod g+s dir     # SGID をシンボリックモードで設定
  chmod +t dir      # Sticky Bit をシンボリックモードで設定
```

### 21.3 umask

```
umask（ファイル作成マスク）:

umask は新しいファイル/ディレクトリのデフォルトパーミッションを決定する。

デフォルトの基本パーミッション:
  ファイル:      666 (rw-rw-rw-)
  ディレクトリ:  777 (rwxrwxrwx)

umask = 022 の場合:
  ファイル:      666 - 022 = 644 (rw-r--r--)
  ディレクトリ:  777 - 022 = 755 (rwxr-xr-x)

umask = 077 の場合（セキュリティ強化）:
  ファイル:      666 - 077 = 600 (rw-------)
  ディレクトリ:  777 - 077 = 700 (rwx------)

# umask の確認
umask
# 出力: 0022

# umask の変更（セッション中のみ）
umask 077

# 永続的な変更
# /etc/profile または ~/.bashrc に追加:
# umask 022

ビット演算の詳細（umask 022 の場合）:
  666:   110 110 110
  022:   000 010 010
  NOT:   111 101 101
  AND:   110 100 100 = 644

  正確には: 結果 = 基本パーミッション AND (NOT umask)
```

---

## 22. Debian パッケージ管理の内部構造

### 22.1 dpkg の仕組み

```
Debian パッケージ管理の階層:

ユーザーインターフェース:
┌──────────────────────────────────────┐
│  apt / apt-get / aptitude            │ ← 高レベルツール
│  ・リポジトリからのダウンロード       │   依存関係の自動解決
│  ・依存関係の自動解決               │
│  ・アップグレードの管理             │
└───────────────┬──────────────────────┘
                │
パッケージ管理:  │
┌───────────────▼──────────────────────┐
│  dpkg                                │ ← 低レベルツール
│  ・.deb パッケージのインストール      │   個別パッケージの管理
│  ・ファイルの展開                    │
│  ・設定スクリプトの実行             │
│  ・パッケージデータベースの管理     │
└──────────────────────────────────────┘

.deb パッケージの構造:
┌──────────────────────────────────────┐
│  package_name_version_arch.deb       │
│  ├── debian-binary                   │ ← フォーマットバージョン (2.0)
│  ├── control.tar.gz                  │ ← メタデータ
│  │   ├── control                     │   パッケージ情報
│  │   ├── md5sums                     │   ファイルのチェックサム
│  │   ├── preinst                     │   インストール前スクリプト
│  │   ├── postinst                    │   インストール後スクリプト
│  │   ├── prerm                       │   削除前スクリプト
│  │   └── postrm                      │   削除後スクリプト
│  └── data.tar.gz                     │ ← 実際のファイル
│      ├── usr/bin/...                 │
│      ├── usr/lib/...                 │
│      ├── etc/...                     │
│      └── usr/share/doc/...           │
└──────────────────────────────────────┘
```

### 22.2 apt の主要コマンド

```bash
# パッケージリストの更新（リポジトリのメタデータを取得）
sudo apt update
# /etc/apt/sources.list のリポジトリから
# パッケージリストをダウンロード

# パッケージのインストール
sudo apt install package_name
# 1. 依存関係を計算
# 2. 必要なパッケージをダウンロード
# 3. dpkg でインストール
# 4. 設定スクリプトを実行

# パッケージの削除
sudo apt remove package_name      # パッケージのみ削除（設定ファイルは残る）
sudo apt purge package_name       # 設定ファイルも含めて完全削除

# システム全体のアップグレード
sudo apt upgrade                  # インストール済みパッケージを更新
sudo apt full-upgrade             # 依存関係の変更を伴う更新も実行

# 不要なパッケージの削除
sudo apt autoremove               # 孤立した依存パッケージを削除

# パッケージの検索
apt search keyword                # キーワードでパッケージを検索
apt show package_name             # パッケージの詳細情報

# インストール済みパッケージの一覧
dpkg -l                           # 全パッケージ
dpkg -l | grep ssh               # ssh 関連のパッケージ

# パッケージが提供するファイルの一覧
dpkg -L openssh-server            # openssh-server のファイル一覧

# ファイルがどのパッケージに属するか
dpkg -S /usr/sbin/sshd            # /usr/sbin/sshd のパッケージ
# openssh-server: /usr/sbin/sshd
```

### 22.3 リポジトリの設定

```bash
# /etc/apt/sources.list の構造:
# タイプ  URI                            ディストリビューション  コンポーネント
# deb     http://deb.debian.org/debian   bookworm               main contrib non-free

# タイプ:
#   deb:     バイナリパッケージ
#   deb-src: ソースパッケージ

# コンポーネント:
#   main:      Debian フリーソフトウェアガイドライン (DFSG) 準拠
#   contrib:   DFSG 準拠だが non-free に依存
#   non-free:  DFSG 非準拠（プロプライエタリ等）

# セキュリティアップデート:
# deb http://security.debian.org/debian-security bookworm-security main
```

---

## 23. /proc ファイルシステム

### 23.1 /proc の概要

`/proc` はカーネルの情報をファイルとして公開する**仮想ファイルシステム**である。ディスク上にデータは存在せず、カーネルがリアルタイムに情報を生成する。monitoring.sh で使用するコマンドの多くは `/proc` の情報を読み取っている。

```
/proc の主要な内容:

/proc/
├── 1/                  ← PID 1 のプロセス情報
│   ├── cmdline         コマンドライン引数
│   ├── cwd → /        カレントディレクトリ
│   ├── environ         環境変数
│   ├── exe → /sbin/init 実行ファイル
│   ├── fd/             開いているファイルディスクリプタ
│   ├── maps            メモリマッピング
│   ├── status          プロセスの詳細状態
│   └── ...
├── cpuinfo             CPU の詳細情報
├── meminfo             メモリの詳細情報
├── version             カーネルバージョン
├── uptime              起動からの経過時間
├── loadavg             ロードアベレージ
├── partitions          パーティション情報
├── filesystems         サポートされるファイルシステム
├── net/                ネットワーク情報
│   ├── tcp             TCP 接続情報
│   ├── udp             UDP 接続情報
│   ├── arp             ARP テーブル
│   └── route           ルーティングテーブル
├── sys/                カーネルパラメータ（sysctl）
│   ├── kernel/         カーネル設定
│   ├── net/            ネットワーク設定
│   │   ├── ipv4/       IPv4 設定
│   │   │   ├── ip_forward           IP フォワーディング
│   │   │   └── tcp_syncookies       SYN Cookie
│   │   └── ipv6/       IPv6 設定
│   ├── fs/             ファイルシステム設定
│   └── vm/             仮想メモリ設定
└── ...
```

### 23.2 monitoring.sh で使用する /proc 情報

```bash
# CPU 情報
cat /proc/cpuinfo
# processor       : 0
# vendor_id       : GenuineIntel
# model name      : Intel(R) Core(TM) i7-...
# cpu MHz         : 2400.000
# cache size      : 8192 KB
# physical id     : 0       ← monitoring.sh で使用
# core id         : 0
# cpu cores       : 4

# メモリ情報
cat /proc/meminfo
# MemTotal:        460000 kB
# MemFree:          15000 kB
# MemAvailable:    283000 kB
# Buffers:          12000 kB
# Cached:          289000 kB
# SwapTotal:      2296000 kB
# SwapFree:       2296000 kB

# 起動時間
cat /proc/uptime
# 12345.67 23456.78
# 最初の数値: システムの起動からの経過秒数
# 2番目の数値: アイドル状態の合計秒数

# ロードアベレージ
cat /proc/loadavg
# 0.15 0.10 0.05 1/120 1234
# 1分  5分  15分 のロードアベレージ
# 実行中プロセス/全プロセス  最新PID

# カーネルバージョン
cat /proc/version
# Linux version 6.1.0-XX-amd64 (debian-kernel@...) (gcc-12 ...) #1 SMP ...
```

### 23.3 sysctl によるカーネルパラメータの変更

```bash
# 現在のパラメータの表示
sysctl -a | head -20
# kernel.hostname = kaztakam42
# kernel.ostype = Linux
# net.ipv4.ip_forward = 0
# ...

# 特定のパラメータの確認
sysctl net.ipv4.ip_forward
# net.ipv4.ip_forward = 0

# パラメータの一時的な変更（再起動で元に戻る）
sudo sysctl -w net.ipv4.ip_forward=1

# パラメータの永続的な変更
# /etc/sysctl.conf に追加:
# net.ipv4.ip_forward = 1
sudo sysctl -p  # 設定を再読み込み

# Born2beRoot に関連するパラメータ:
# net.ipv4.ip_forward = 0          IP フォワーディング無効（ルーターでない）
# net.ipv4.tcp_syncookies = 1      SYN フラッド攻撃対策
# kernel.randomize_va_space = 2    ASLR（メモリレイアウトのランダム化）
# fs.protected_symlinks = 1        シンボリックリンク攻撃の防止
# fs.protected_hardlinks = 1       ハードリンク攻撃の防止
```

---

## 24. ログ管理

### 24.1 Linux のログシステム

```
Linux のログアーキテクチャ:

┌──────────────────────────────────────────┐
│  アプリケーション / サービス              │
│  (sshd, cron, sudo, ...)                │
│       │              │                   │
│       │ syslog       │ journald          │
│       ▼              ▼                   │
│  ┌────────┐     ┌──────────┐            │
│  │ rsyslog│     │ journald │            │
│  │        │←────│ (systemd)│            │
│  └───┬────┘     └────┬─────┘            │
│      │               │                   │
│      ▼               ▼                   │
│  /var/log/       バイナリDB              │
│  ├── syslog      /var/log/journal/       │
│  ├── auth.log                            │
│  ├── kern.log                            │
│  ├── daemon.log                          │
│  └── ...                                 │
└──────────────────────────────────────────┘
```

### 24.2 重要なログファイル

```bash
# 認証関連ログ（SSH ログイン、sudo 使用）
/var/log/auth.log
# 例:
# Jan 15 10:00:00 kaztakam42 sshd[200]: Accepted password for kaztakam
# Jan 15 10:05:00 kaztakam42 sudo:  kaztakam : TTY=pts/0 ; COMMAND=/usr/bin/apt update
# Jan 15 10:10:00 kaztakam42 sshd[300]: Failed password for invalid user attacker

# システムログ（一般的なシステムイベント）
/var/log/syslog
# cron の実行、サービスの起動/停止等

# カーネルログ
/var/log/kern.log
# ハードウェアエラー、ドライバメッセージ

# sudo ログ（Born2beRoot の設定による）
/var/log/sudo/sudo.log
# sudo コマンドの使用履歴

# journald でのログ閲覧
journalctl                        # 全てのログ
journalctl -u sshd                # sshd のログ
journalctl -u cron                # cron のログ
journalctl _COMM=sudo             # sudo コマンドのログ
journalctl --since "1 hour ago"   # 直近1時間のログ
journalctl -b                     # 最新のブートからのログ
journalctl -p err                 # エラー以上のログ
journalctl -f                     # リアルタイムでログを表示（tail -f 相当）

# ログのローテーション
# /etc/logrotate.conf: グローバル設定
# /etc/logrotate.d/: 個別のサービス設定
#
# logrotate の動作:
# 1. 古いログファイルを圧縮（gzip）
# 2. ログファイルをリネーム（.1, .2, .3, ...）
# 3. 新しい空のログファイルを作成
# 4. 指定世代数を超えた古いログを削除
```

### 24.3 Born2beRoot でのログ監視

```bash
# SSH のログイン失敗を監視
grep "Failed password" /var/log/auth.log
# 不正なログイン試行の検知

# sudo の使用履歴を監視
cat /var/log/sudo/sudo.log
# 誰が何のコマンドを実行したか

# cron の実行を監視
grep CRON /var/log/syslog
# monitoring.sh が正しく実行されているか

# AppArmor のブロックを監視
dmesg | grep apparmor
# または
journalctl -k | grep apparmor
# MAC ポリシー違反の検知

# ディスク使用量の監視
df -h
# /var/log パーティションの使用率

# ログの行数でログ爆発を検知
wc -l /var/log/auth.log
# 異常に多い場合はブルートフォース攻撃の可能性
```

---

## 25. シェルスクリプトの基礎（monitoring.sh 理解のために）

### 25.1 シェルスクリプトの構造

```bash
#!/bin/bash
# ↑ シバン (shebang): スクリプトを実行するインタプリタを指定
# /bin/bash: Bourne Again Shell を使用
# /bin/sh:   POSIX 互換シェルを使用（より移植性が高い）

# 変数の定義と使用
name="Born2beRoot"     # = の前後にスペースなし（重要！）
echo "Project: $name"  # 変数の展開
echo "Project: ${name}" # 中括弧での変数展開（推奨）

# コマンド置換
current_date=$(date +%Y-%m-%d)  # $() 形式（推奨）
current_date=`date +%Y-%m-%d`   # バッククォート形式（古い形式）

# 算術演算
count=$((5 + 3))       # 算術展開
result=$((100 / 3))    # 整数除算（結果: 33）
```

### 25.2 条件分岐

```bash
# if 文
if [ condition ]; then
    command1
elif [ condition2 ]; then
    command2
else
    command3
fi

# テスト条件:
# 文字列比較:
#   [ "$a" = "$b" ]     等しい
#   [ "$a" != "$b" ]    等しくない
#   [ -z "$a" ]         空文字列
#   [ -n "$a" ]         非空文字列

# 数値比較:
#   [ "$a" -eq "$b" ]   等しい (equal)
#   [ "$a" -ne "$b" ]   等しくない (not equal)
#   [ "$a" -gt "$b" ]   より大きい (greater than)
#   [ "$a" -lt "$b" ]   より小さい (less than)
#   [ "$a" -ge "$b" ]   以上 (greater or equal)
#   [ "$a" -le "$b" ]   以下 (less or equal)

# ファイルテスト:
#   [ -f "$file" ]      通常ファイルが存在する
#   [ -d "$dir" ]       ディレクトリが存在する
#   [ -e "$path" ]      パスが存在する
#   [ -r "$file" ]      読み取り可能
#   [ -w "$file" ]      書き込み可能
#   [ -x "$file" ]      実行可能
#   [ -s "$file" ]      サイズが0より大きい

# monitoring.sh での使用例:
lvm_use=$(if [ $(lsblk | grep -c "lvm") -gt 0 ]; then echo yes; else echo no; fi)
```

### 25.3 パイプとリダイレクション

```bash
# パイプ（|）: コマンドの出力を次のコマンドの入力に接続
command1 | command2 | command3

# monitoring.sh での使用例:
grep "physical id" /proc/cpuinfo | sort -u | wc -l
#                                     │        │      │
# /proc/cpuinfo から physical id 行を抽出──┘        │      │
#                              重複を除去──────┘      │
#                                        行数をカウント──┘

# リダイレクション:
command > file      # 標準出力をファイルに上書き
command >> file     # 標準出力をファイルに追記
command 2> file     # 標準エラー出力をファイルに書き込み
command 2>&1        # 標準エラーを標準出力にマージ
command > /dev/null # 出力を破棄
command 2>/dev/null # エラー出力を破棄
command < file      # ファイルから標準入力に読み込み

# monitoring.sh での使用例:
sudo_count=$(journalctl _COMM=sudo 2>/dev/null | grep -c "COMMAND")
# 2>/dev/null: journalctl のエラーメッセージを破棄
```

### 25.4 テキスト処理コマンド

```bash
# grep: パターンマッチング
grep "pattern" file          # パターンを含む行を表示
grep -c "pattern" file       # マッチした行数をカウント
grep -v "pattern" file       # パターンを含まない行を表示
grep -E "pat1|pat2" file     # 拡張正規表現（OR検索）
grep "^pattern" file         # 行頭がパターンの行

# awk: フィールド処理
awk '{print $1}' file        # 各行の1番目のフィールド
awk '/Mem:/ {print $2}' file # "Mem:" を含む行の2番目のフィールド
awk '{printf("%.2f"), $3/$2*100}' # 計算とフォーマット出力

# monitoring.sh での awk 使用例:
free -m | awk '/Mem:/ {print $3}'       # 使用中メモリ (MB)
free -m | awk '/Mem:/ {printf("%.2f"), $3/$2*100}'  # メモリ使用率 (%)

# sed: ストリームエディタ
sed 's/old/new/' file        # 最初のマッチを置換
sed 's/old/new/g' file       # 全てのマッチを置換
sed -n '5p' file             # 5行目のみ表示
sed '3d' file                # 3行目を削除

# tr: 文字の変換・削除
echo "HELLO" | tr 'A-Z' 'a-z'     # 大文字を小文字に
echo "123G" | tr -d 'G'           # 'G' を削除 → "123"

# monitoring.sh での使用例:
df -BG --total | awk '/^total/ {print $2}' | tr -d 'G'  # "4G" → "4"

# sort: ソート
sort file                    # 昇順ソート
sort -u file                 # ソートして重複を除去
sort -n file                 # 数値としてソート
sort -r file                 # 降順ソート

# wc: カウント
wc -l file                   # 行数
wc -w file                   # 単語数
wc -c file                   # バイト数

# head / tail: 先頭/末尾の行
head -5 file                 # 先頭5行
tail -5 file                 # 末尾5行
tail -f file                 # リアルタイムで末尾を追跡

# cut: フィールドの切り出し
cut -d: -f1 /etc/passwd      # ':' で区切られた1番目のフィールド
```

---

## 26. セキュリティのベストプラクティス

### 26.1 多層防御の概念

Born2beRoot で実装するセキュリティは、**多層防御 (Defense in Depth)** の考え方に基づく。一つの防御が破られても、次の層が攻撃を阻止する。

```
Born2beRoot の多層防御モデル:

外部攻撃者
    │
    ▼
┌──────────────────────────────────────────────────┐
│ Layer 7: 物理層 (Physical)                        │
│   LUKS ディスク暗号化                              │
│   → ディスクの物理的盗取からデータを保護           │
├──────────────────────────────────────────────────┤
│ Layer 6: ネットワーク層 (Network)                  │
│   UFW ファイアウォール (port 4242 のみ)            │
│   → ネットワーク経由の攻撃面を最小化              │
├──────────────────────────────────────────────────┤
│ Layer 5: 認証層 (Authentication)                   │
│   SSH: root 禁止、ポート変更                      │
│   パスワードポリシー: 10文字以上、文字種混合       │
│   → 不正ログインの困難化                          │
├──────────────────────────────────────────────────┤
│ Layer 4: 権限管理層 (Authorization)                │
│   sudo: 3回制限、TTY必須、PATH制限                │
│   ファイルパーミッション: DAC (rwx)               │
│   → 権限昇格の防止                               │
├──────────────────────────────────────────────────┤
│ Layer 3: 強制アクセス制御層 (MAC)                  │
│   AppArmor: プロセスごとのアクセス制限            │
│   → 乗っ取られたプロセスの被害範囲を限定          │
├──────────────────────────────────────────────────┤
│ Layer 2: 監査層 (Auditing)                         │
│   sudo ログ (入力/出力記録)                       │
│   auth.log、journald                             │
│   → 事後追跡 (フォレンジック)                     │
├──────────────────────────────────────────────────┤
│ Layer 1: 監視層 (Monitoring)                       │
│   monitoring.sh + cron (10分間隔)                  │
│   → 異常の早期検知                               │
├──────────────────────────────────────────────────┤
│ Layer 0: ストレージ層 (Storage)                     │
│   パーティション分離 (/var/log, /tmp)              │
│   → ログ爆発攻撃・/tmp 実行攻撃からの保護        │
└──────────────────────────────────────────────────┘
    │
    ▼
保護されたデータ
```

### 26.2 最小権限の原則 (Principle of Least Privilege)

```
最小権限の原則: ユーザーやプロセスには、タスクを完了するために
必要な最小限の権限のみを付与する。

Born2beRoot での実装:

1. root SSH ログイン禁止
   → 管理者は一般ユーザーとしてログインし、必要時のみ sudo を使用

2. sudo の制限
   → 全ユーザーが root になれるわけではない（sudo グループのみ）
   → コマンドごとの制限も可能（sudoers で設定）

3. UFW ファイアウォール
   → 必要なポート (4242) のみ開放
   → デフォルト拒否 (deny incoming)

4. AppArmor プロファイル
   → 各プロセスに必要最小限のファイルアクセスのみ許可

5. ファイルパーミッション
   → /etc/shadow は root のみ読み取り可能 (640)
   → /etc/sudoers.d/ は root のみアクセス可能 (440)
   → ホームディレクトリは所有者のみアクセス可能 (700)
```

### 26.3 CIA トライアド（情報セキュリティの3要素）

```
情報セキュリティの3つの柱（CIA）:

     ┌───────────────────────────┐
     │   Confidentiality         │
     │   (機密性)                │
     │   情報を許可された人のみ   │
     │   がアクセスできること     │
     │                           │
     │   Born2beRoot での実装:   │
     │   - LUKS 暗号化          │
     │   - ファイルパーミッション │
     │   - AppArmor             │
     └─────────┬─────────────────┘
               │
    ┌──────────┴──────────┐
    ▼                     ▼
┌────────────────┐ ┌────────────────┐
│ Integrity      │ │ Availability   │
│ (完全性)       │ │ (可用性)       │
│ 情報が改ざん   │ │ 情報が必要な時 │
│ されていない   │ │ にアクセス可能 │
│ こと           │ │ であること     │
│                │ │                │
│ Born2beRoot:   │ │ Born2beRoot:   │
│ - sudo ログ   │ │ - パーティション│
│ - AppArmor    │ │   分離         │
│ - /etc/shadow │ │ - monitoring.sh│
│   のハッシュ  │ │ - cron の定期  │
│               │ │   実行         │
└────────────────┘ └────────────────┘
```

---

## 27. 実践コマンドリファレンス

### 27.1 システム情報の確認

```bash
# OS バージョン
cat /etc/os-release
lsb_release -a

# カーネルバージョン
uname -r              # カーネルリリース
uname -a              # 全情報

# ホスト名
hostname
hostnamectl

# 起動時間
uptime
# 出力: 10:30:00 up 2 days, 3:15, 1 user, load average: 0.15, 0.10, 0.05

# ハードウェア情報
lscpu                 # CPU 情報
free -h               # メモリ情報（人間が読みやすい形式）
lsblk                 # ブロックデバイス
df -h                 # ディスク使用量
```

### 27.2 ネットワークの確認

```bash
# IP アドレス
ip addr show
hostname -I

# ルーティング
ip route show

# 開いているポート
ss -tunlp             # TCP/UDP のリスニングポート
# -t: TCP
# -u: UDP
# -n: 数値表示（名前解決しない）
# -l: リスニングソケットのみ
# -p: プロセス名を表示

# 接続中のセッション
ss -t state established

# DNS の確認
cat /etc/resolv.conf
```

### 27.3 サービス管理

```bash
# サービスの状態確認
sudo systemctl status sshd
sudo systemctl status ufw
sudo systemctl status cron
sudo systemctl status apparmor

# サービスの操作
sudo systemctl start SERVICE
sudo systemctl stop SERVICE
sudo systemctl restart SERVICE
sudo systemctl reload SERVICE

# 自動起動の管理
sudo systemctl enable SERVICE
sudo systemctl disable SERVICE
sudo systemctl is-enabled SERVICE

# 全サービスの一覧
systemctl list-units --type=service
systemctl list-units --type=service --state=running
```

### 27.4 パッケージ管理

```bash
# パッケージリストの更新
sudo apt update

# パッケージのインストール
sudo apt install PACKAGE

# パッケージの削除
sudo apt remove PACKAGE
sudo apt purge PACKAGE

# システムのアップグレード
sudo apt upgrade

# インストール済みパッケージの確認
dpkg -l | grep KEYWORD
dpkg -l PACKAGE

# パッケージの詳細
apt show PACKAGE

# 不要パッケージの削除
sudo apt autoremove
```

### 27.5 ユーザー・グループ管理

```bash
# ユーザー作成
sudo adduser USERNAME

# グループ作成
sudo groupadd GROUPNAME

# グループへの追加
sudo usermod -aG GROUP USERNAME

# ユーザー情報の確認
id USERNAME
groups USERNAME
getent group GROUPNAME

# パスワードポリシーの確認
sudo chage -l USERNAME

# パスワード変更
sudo passwd USERNAME
```

### 27.6 セキュリティの確認

```bash
# AppArmor
sudo aa-status

# UFW
sudo ufw status verbose
sudo ufw status numbered

# SSH
sudo systemctl status sshd
sudo ss -tunlp | grep ssh
grep "^Port" /etc/ssh/sshd_config
grep "^PermitRootLogin" /etc/ssh/sshd_config

# sudo 設定
sudo cat /etc/sudoers.d/sudo_config
sudo visudo -c

# パスワードポリシー
grep "^PASS" /etc/login.defs
grep "pam_pwquality" /etc/pam.d/common-password

# LUKS 暗号化
sudo cryptsetup status sda5_crypt
lsblk | grep crypt

# LVM
sudo pvdisplay
sudo vgdisplay
sudo lvdisplay
```

---

## まとめ

Born2beRoot プロジェクトは、以下の Linux システム管理の基礎を実践的に学ぶための課題である:

1. **仮想化**: VM の概念と Hypervisor の理解、CPU保護リングの仕組み、メインフレーム時代から現代のクラウドまでの仮想化の歴史、コンテナ仮想化との比較
2. **OS インストール**: Debian/Rocky の手動インストール、ブートプロセスの全体像（BIOS → GRUB → initramfs → systemd）
3. **ネットワーク**: TCP/IP 4層モデル、3ウェイハンドシェイク、ソケット通信、DNS、ルーティング、サブネットマスク計算
4. **ストレージ管理**: LVM の PE/LE マッピング、ext4 の inode 構造とジャーナリング、LUKS/dm-crypt による暗号化フローの詳細
5. **セキュリティ**: ファイアウォール（Netfilter/iptables/UFW のフック処理）、SSH の暗号化プロトコル（DH鍵交換）、sudo の制限と監査、多層防御の設計
6. **アクセス制御**: DAC（パーミッション、umask、SUID/SGID/Sticky Bit）、MAC（AppArmor/SELinux）、LSM の多層構造、Capabilities
7. **システム管理**: systemd のユニットファイル構造・依存関係・ジャーナル、cron によるタスクスケジューリング、プロセス管理
8. **監視**: シェルスクリプトと cron によるシステム監視、/proc からの情報取得、ログ管理
9. **認証**: パスワードのエントロピーと強度、PAM フレームワークによるパスワードポリシー
10. **ユーザー管理**: UID/GID の体系、/etc/passwd と /etc/shadow の構造、グループ管理
11. **パッケージ管理**: dpkg の仕組み、apt と aptitude の違い、リポジトリの構成

これらは実際のサーバー管理で日常的に使用される知識であり、このプロジェクトを通じてシステム管理者としての堅固な基礎を築くことができる。
